================================================================================
model.embeddings                         CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[ 0.00988770,  0.02526855, -0.01232910,  ...,  0.04296875,
          0.00503540, -0.02355957],
        [-0.00909424,  0.03686523, -0.01818848,  ..., -0.00622559,
          0.00150299, -0.01904297],
        [ 0.04296875, -0.02148438,  0.01367188,  ...,  0.00154877,
          0.00049591,  0.00421143],
        ...,
        [ 0.00570679,  0.01208496, -0.00485229,  ...,  0.02563477,
         -0.00531006, -0.01361084],
        [ 0.04296875, -0.02148438,  0.01367188,  ...,  0.00154877,
          0.00049591,  0.00421143],
        [-0.11816406, -0.01794434,  0.00714111,  ...,  0.00056839,
         -0.00091171,  0.00037193]], dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 0.00988770,  0.02526855, -0.01232910,  ...,  0.04296875,
          0.00503540, -0.02355957],
        [-0.00909424,  0.03686523, -0.01818848,  ..., -0.00622559,
          0.00150299, -0.01904297],
        [ 0.04296875, -0.02148438,  0.01367188,  ...,  0.00154877,
          0.00049591,  0.00421143],
        ...,
        [ 0.00570679,  0.01208496, -0.00485229,  ...,  0.02563477,
         -0.00531006, -0.01361084],
        [ 0.04296875, -0.02148438,  0.01367188,  ...,  0.00154877,
          0.00049591,  0.00421143],
        [-0.11816406, -0.01794434,  0.00714111,  ...,  0.00056839,
         -0.00091171,  0.00037193]], dtype=torch.bfloat16)
================================================================================
model.last_layernorm                     CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[ 7.81250000e-02, -2.78320312e-02,  2.90527344e-02,  ...,
         -1.64062500e-01, -4.64843750e-01, -1.18164062e-01],
        [-9.06250000e-01, -3.85742188e-02,  2.83203125e-02,  ...,
         -2.19726562e-03, -1.31225586e-02, -1.09863281e-03],
        [-7.65625000e-01, -2.40478516e-02,  7.81250000e-02,  ...,
          5.12695312e-03,  1.73339844e-02, -4.27246094e-04],
        ...,
        [-8.00781250e-01,  7.17773438e-02,  2.44140625e-02,  ...,
          1.72119141e-02,  3.47900391e-03, -7.35473633e-03],
        [-8.16406250e-01,  6.10351562e-05,  6.83593750e-02,  ...,
          7.20214844e-03, -7.75146484e-03, -8.42285156e-03],
        [-1.18750000e+00,  8.66699219e-03, -1.29394531e-02,  ...,
         -9.39941406e-03, -2.02636719e-02,  2.94494629e-03]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 7.81250000e-02, -2.78320312e-02,  2.90527344e-02,  ...,
         -1.64062500e-01, -4.64843750e-01, -1.18164062e-01],
        [-9.06250000e-01, -3.85742188e-02,  2.83203125e-02,  ...,
         -2.19726562e-03, -1.31225586e-02, -1.09863281e-03],
        [-7.65625000e-01, -2.40478516e-02,  7.81250000e-02,  ...,
          5.12695312e-03,  1.73339844e-02, -4.27246094e-04],
        ...,
        [-8.00781250e-01,  7.17773438e-02,  2.44140625e-02,  ...,
          1.72119141e-02,  3.47900391e-03, -7.35473633e-03],
        [-8.16406250e-01,  6.10351562e-05,  6.83593750e-02,  ...,
          7.20214844e-03, -7.75146484e-03, -8.42285156e-03],
        [-1.18750000e+00,  8.66699219e-03, -1.29394531e-02,  ...,
         -9.39941406e-03, -2.02636719e-02,  2.94494629e-03]],
       dtype=torch.bfloat16)
================================================================================
model.layer[0].input                     CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[ 0.00988770,  0.02526855, -0.01232910,  ...,  0.04296875,
          0.00503540, -0.02355957],
        [-0.00909424,  0.03686523, -0.01818848,  ..., -0.00622559,
          0.00150299, -0.01904297],
        [ 0.04296875, -0.02148438,  0.01367188,  ...,  0.00154877,
          0.00049591,  0.00421143],
        ...,
        [ 0.00570679,  0.01208496, -0.00485229,  ...,  0.02563477,
         -0.00531006, -0.01361084],
        [ 0.04296875, -0.02148438,  0.01367188,  ...,  0.00154877,
          0.00049591,  0.00421143],
        [-0.11816406, -0.01794434,  0.00714111,  ...,  0.00056839,
         -0.00091171,  0.00037193]], dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 0.00988770,  0.02526855, -0.01232910,  ...,  0.04296875,
          0.00503540, -0.02355957],
        [-0.00909424,  0.03686523, -0.01818848,  ..., -0.00622559,
          0.00150299, -0.01904297],
        [ 0.04296875, -0.02148438,  0.01367188,  ...,  0.00154877,
          0.00049591,  0.00421143],
        ...,
        [ 0.00570679,  0.01208496, -0.00485229,  ...,  0.02563477,
         -0.00531006, -0.01361084],
        [ 0.04296875, -0.02148438,  0.01367188,  ...,  0.00154877,
          0.00049591,  0.00421143],
        [-0.11816406, -0.01794434,  0.00714111,  ...,  0.00056839,
         -0.00091171,  0.00037193]], dtype=torch.bfloat16)
================================================================================
model.layer[0].input_norm                CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[ 2.12097168e-03,  5.30242920e-04, -6.83593750e-03,  ...,
          1.72424316e-03,  4.04357910e-04, -1.76239014e-03],
        [-1.91497803e-03,  7.55310059e-04, -9.82666016e-03,  ...,
         -2.44140625e-04,  1.17778778e-04, -1.38854980e-03],
        [ 1.22070312e-02, -5.95092773e-04,  1.00097656e-02,  ...,
          8.20159912e-05,  5.24520874e-05,  4.13894653e-04],
        ...,
        [ 1.16729736e-03,  2.41279602e-04, -2.56347656e-03,  ...,
          9.84191895e-04, -4.06265259e-04, -9.68933105e-04],
        [ 1.22070312e-02, -5.95092773e-04,  1.00097656e-02,  ...,
          8.20159912e-05,  5.24520874e-05,  4.13894653e-04],
        [-4.41894531e-02, -6.56127930e-04,  6.89697266e-03,  ...,
          3.98159027e-05, -1.27792358e-04,  4.83989716e-05]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 2.12097168e-03,  5.30242920e-04, -6.83593750e-03,  ...,
          1.72424316e-03,  4.04357910e-04, -1.76239014e-03],
        [-1.91497803e-03,  7.55310059e-04, -9.82666016e-03,  ...,
         -2.44140625e-04,  1.17778778e-04, -1.38854980e-03],
        [ 1.22070312e-02, -5.95092773e-04,  1.00097656e-02,  ...,
          8.20159912e-05,  5.24520874e-05,  4.13894653e-04],
        ...,
        [ 1.16729736e-03,  2.41279602e-04, -2.56347656e-03,  ...,
          9.84191895e-04, -4.06265259e-04, -9.68933105e-04],
        [ 1.22070312e-02, -5.95092773e-04,  1.00097656e-02,  ...,
          8.20159912e-05,  5.24520874e-05,  4.13894653e-04],
        [-4.41894531e-02, -6.56127930e-04,  6.89697266e-03,  ...,
          3.98159027e-05, -1.27792358e-04,  4.83989716e-05]],
       dtype=torch.bfloat16)
================================================================================
model.layer[0].mlp                       CHECK_SUCCESS: False eq_num/sum: 31830/106496
============================================================
tensor([[ 0.01324463,  0.00787354, -0.03100586,  ...,  0.01367188,
         -0.00170898, -0.00463867],
        [ 0.00848389,  0.00637817, -0.02099609,  ...,  0.00738525,
         -0.00176239, -0.00033569],
        [ 0.01110840,  0.00314331, -0.01080322,  ...,  0.00631714,
         -0.00201416, -0.00166321],
        ...,
        [-0.00082779, -0.00064850, -0.00367737,  ..., -0.00109100,
          0.00068283, -0.00095749],
        [ 0.00128937,  0.00079727, -0.00113678,  ...,  0.00072861,
          0.00018024,  0.00010824],
        [ 0.00946045, -0.00311279,  0.01141357,  ..., -0.00212097,
         -0.00170898,  0.00176239]], dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 0.01324463,  0.00787354, -0.03063965,  ...,  0.01367188,
         -0.00170135, -0.00463867],
        [ 0.00866699,  0.00637817, -0.02075195,  ...,  0.00738525,
         -0.00176239, -0.00032425],
        [ 0.01116943,  0.00315857, -0.01074219,  ...,  0.00631714,
         -0.00201416, -0.00166321],
        ...,
        [-0.00083160, -0.00063324, -0.00355530,  ..., -0.00109100,
          0.00068283, -0.00095749],
        [ 0.00130463,  0.00080109, -0.00115967,  ...,  0.00072479,
          0.00017929,  0.00011063],
        [ 0.00939941, -0.00309753,  0.01165771,  ..., -0.00215149,
         -0.00170898,  0.00176239]], dtype=torch.bfloat16)
================================================================================
model.layer[0].mlp.act_out               CHECK_SUCCESS: True eq_num/sum: 372736/372736
============================================================
tensor([[-1.75476074e-04, -1.48773193e-04,  1.37090683e-05,  ...,
         -9.87052917e-05,  1.12533569e-04,  5.14984131e-05],
        [ 8.96453857e-05,  1.40190125e-04, -6.29425049e-05,  ...,
         -5.75184822e-06,  9.48905945e-05,  6.38961792e-05],
        [-4.46319580e-04, -2.72989273e-05, -1.32560730e-04,  ...,
         -3.07559967e-05,  4.32968140e-04,  1.00612640e-04],
        ...,
        [ 2.43186951e-05,  1.95503235e-04, -1.85966492e-04,  ...,
         -4.74974513e-07,  3.75747681e-04,  7.72476196e-05],
        [-5.86509705e-05,  1.47819519e-04, -2.68936157e-04,  ...,
          2.08616257e-06,  1.01089478e-04,  1.51395798e-05],
        [-8.30078125e-02,  2.02636719e-02, -4.15039062e-02,  ...,
         -1.35302544e-05,  2.25067139e-04,  4.29153442e-05]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[-1.75476074e-04, -1.48773193e-04,  1.37090683e-05,  ...,
         -9.87052917e-05,  1.12533569e-04,  5.14984131e-05],
        [ 8.96453857e-05,  1.40190125e-04, -6.29425049e-05,  ...,
         -5.75184822e-06,  9.48905945e-05,  6.38961792e-05],
        [-4.46319580e-04, -2.72989273e-05, -1.32560730e-04,  ...,
         -3.07559967e-05,  4.32968140e-04,  1.00612640e-04],
        ...,
        [ 2.43186951e-05,  1.95503235e-04, -1.85966492e-04,  ...,
         -4.74974513e-07,  3.75747681e-04,  7.72476196e-05],
        [-5.86509705e-05,  1.47819519e-04, -2.68936157e-04,  ...,
          2.08616257e-06,  1.01089478e-04,  1.51395798e-05],
        [-8.30078125e-02,  2.02636719e-02, -4.15039062e-02,  ...,
         -1.35302544e-05,  2.25067139e-04,  4.29153442e-05]],
       dtype=torch.bfloat16)
================================================================================
model.layer[0].mlp.gate_up_out           CHECK_SUCCESS: False eq_num/sum: 152039/745472
============================================================
tensor([[-2.17285156e-02,  1.70898438e-02,  1.17492676e-03,  ...,
         -1.68457031e-02, -8.91113281e-03,  5.43212891e-03],
        [-6.74438477e-03,  1.92871094e-02,  1.01318359e-02,  ...,
         -3.06701660e-03, -1.54418945e-02,  8.91113281e-03],
        [-3.14941406e-02,  6.31713867e-03, -1.23901367e-02,  ...,
         -1.12915039e-02, -2.36816406e-02,  1.18408203e-02],
        ...,
        [ 1.12152100e-03, -9.88769531e-03, -8.11767578e-03,  ...,
          3.96728516e-04, -2.18505859e-02,  1.39160156e-02],
        [-2.41088867e-03, -1.08642578e-02, -1.67236328e-02,  ...,
         -1.64031982e-03, -1.26342773e-02,  6.34765625e-03],
        [-4.70703125e-01, -2.12890625e-01, -3.20312500e-01,  ...,
          4.05883789e-03, -2.42919922e-02,  9.52148438e-03]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[-2.27050781e-02,  1.74560547e-02,  1.48773193e-03,  ...,
         -1.67236328e-02, -8.91113281e-03,  5.46264648e-03],
        [-7.17163086e-03,  1.92871094e-02,  1.01318359e-02,  ...,
         -3.05175781e-03, -1.55029297e-02,  9.09423828e-03],
        [-3.19824219e-02,  6.28662109e-03, -1.17797852e-02,  ...,
         -1.12304688e-02, -2.36816406e-02,  1.19018555e-02],
        ...,
        [ 1.46484375e-03, -9.70458984e-03, -7.72094727e-03,  ...,
          3.79562378e-04, -2.16064453e-02,  1.39770508e-02],
        [-2.88391113e-03, -1.08642578e-02, -1.63574219e-02,  ...,
         -1.56402588e-03, -1.25732422e-02,  6.37817383e-03],
        [-4.70703125e-01, -2.12890625e-01, -3.20312500e-01,  ...,
          4.21142578e-03, -2.40478516e-02,  9.46044922e-03]],
       dtype=torch.bfloat16)
================================================================================
model.layer[0].post_norm                 CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[ 2.34375000e-02, -6.14166260e-04, -1.20605469e-01,  ...,
          4.46777344e-02, -8.01086426e-04, -4.27246094e-03],
        [ 3.31115723e-03, -7.51495361e-04, -2.55859375e-01,  ...,
          3.49426270e-03, -4.65393066e-04, -3.28063965e-03],
        [ 8.34960938e-02,  6.82830811e-04,  1.70898438e-01,  ...,
          8.72802734e-03, -5.68389893e-04,  2.72989273e-05],
        ...,
        [ 1.14746094e-02, -3.37600708e-04, -8.44726562e-02,  ...,
          2.73437500e-02,  4.11987305e-04, -2.04467773e-03],
        [ 8.59375000e-02,  6.44683838e-04,  1.96289062e-01,  ...,
          9.61303711e-04, -1.17778778e-04,  5.87463379e-04],
        [-2.96875000e-01,  6.79016113e-04,  1.04003906e-01,  ...,
         -1.30462646e-03,  5.26905060e-05, -1.19209290e-04]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 2.34375000e-02, -6.14166260e-04, -1.20605469e-01,  ...,
          4.46777344e-02, -8.01086426e-04, -4.27246094e-03],
        [ 3.31115723e-03, -7.51495361e-04, -2.55859375e-01,  ...,
          3.49426270e-03, -4.65393066e-04, -3.28063965e-03],
        [ 8.34960938e-02,  6.82830811e-04,  1.70898438e-01,  ...,
          8.72802734e-03, -5.68389893e-04,  2.72989273e-05],
        ...,
        [ 1.14746094e-02, -3.37600708e-04, -8.44726562e-02,  ...,
          2.73437500e-02,  4.11987305e-04, -2.04467773e-03],
        [ 8.59375000e-02,  6.44683838e-04,  1.96289062e-01,  ...,
          9.61303711e-04, -1.17778778e-04,  5.87463379e-04],
        [-2.96875000e-01,  6.79016113e-04,  1.04003906e-01,  ...,
         -1.30462646e-03,  5.26905060e-05, -1.19209290e-04]],
       dtype=torch.bfloat16)
================================================================================
model.layer[0].post_norm_residual        CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[ 0.01721191,  0.02600098, -0.01025391,  ...,  0.04272461,
          0.01049805, -0.03222656],
        [ 0.00244141,  0.03198242, -0.02185059,  ...,  0.00335693,
          0.00613403, -0.02490234],
        [ 0.04541016, -0.02148438,  0.01080322,  ...,  0.00616455,
          0.00552368,  0.00015259],
        ...,
        [ 0.00811768,  0.01385498, -0.00695801,  ...,  0.02514648,
         -0.00521851, -0.01483154],
        [ 0.04394531, -0.01904297,  0.01165771,  ...,  0.00064087,
          0.00107574,  0.00308228],
        [-0.11425781, -0.01513672,  0.00463867,  ..., -0.00065231,
         -0.00036240, -0.00047112]], dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 0.01721191,  0.02600098, -0.01025391,  ...,  0.04272461,
          0.01049805, -0.03222656],
        [ 0.00244141,  0.03198242, -0.02185059,  ...,  0.00335693,
          0.00613403, -0.02490234],
        [ 0.04541016, -0.02148438,  0.01080322,  ...,  0.00616455,
          0.00552368,  0.00015259],
        ...,
        [ 0.00811768,  0.01385498, -0.00695801,  ...,  0.02514648,
         -0.00521851, -0.01483154],
        [ 0.04394531, -0.01904297,  0.01165771,  ...,  0.00064087,
          0.00107574,  0.00308228],
        [-0.11425781, -0.01513672,  0.00463867,  ..., -0.00065231,
         -0.00036240, -0.00047112]], dtype=torch.bfloat16)
================================================================================
model.layer[0].self_attn                 CHECK_SUCCESS: False eq_num/sum: 35335/106496
============================================================
tensor([[ 7.35473633e-03,  6.75201416e-04,  2.07519531e-03,  ...,
         -2.11715698e-04,  5.49316406e-03, -8.72802734e-03],
        [ 1.15356445e-02, -4.91333008e-03, -3.69262695e-03,  ...,
          9.58251953e-03,  4.63867188e-03, -5.88989258e-03],
        [ 2.31933594e-03, -4.41074371e-05, -2.85339355e-03,  ...,
          4.60815430e-03,  5.03540039e-03, -4.05883789e-03],
        ...,
        [ 2.41088867e-03,  1.77001953e-03, -2.10571289e-03,  ...,
         -5.11169434e-04,  1.01089478e-04, -1.19781494e-03],
        [ 8.62121582e-04,  2.42614746e-03, -2.02941895e-03,  ...,
         -9.07897949e-04,  5.79833984e-04, -1.13677979e-03],
        [ 4.02832031e-03,  2.77709961e-03, -2.51770020e-03,  ...,
         -1.22070312e-03,  5.49316406e-04, -8.43048096e-04]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 7.26318359e-03,  6.59942627e-04,  2.12097168e-03,  ...,
         -3.29971313e-04,  5.52368164e-03, -8.72802734e-03],
        [ 1.15966797e-02, -4.91333008e-03, -3.67736816e-03,  ...,
          9.58251953e-03,  4.63867188e-03, -5.88989258e-03],
        [ 2.31933594e-03, -4.14848328e-05, -2.85339355e-03,  ...,
          4.57763672e-03,  5.03540039e-03, -4.05883789e-03],
        ...,
        [ 2.38037109e-03,  1.77764893e-03, -2.10571289e-03,  ...,
         -5.34057617e-04,  1.01566315e-04, -1.20544434e-03],
        [ 8.23974609e-04,  2.44140625e-03, -2.02941895e-03,  ...,
         -9.30786133e-04,  5.79833984e-04, -1.13677979e-03],
        [ 3.99780273e-03,  2.79235840e-03, -2.51770020e-03,  ...,
         -1.24359131e-03,  5.49316406e-04, -8.43048096e-04]],
       dtype=torch.bfloat16)
================================================================================
model.layer[0].self_attn.attn_out        CHECK_SUCCESS: False eq_num/sum: 106159/106496
============================================================
tensor([[ 0.00343323,  0.00285339,  0.00128937,  ...,  0.00023365,
         -0.00445557, -0.00337219],
        [ 0.00317383,  0.00127411,  0.00122070,  ...,  0.00064087,
         -0.00306702, -0.00139618],
        [ 0.00247192,  0.00088120,  0.00091934,  ...,  0.00071716,
         -0.00253296, -0.00112915],
        ...,
        [ 0.00138855,  0.00093842,  0.00025368,  ...,  0.00053787,
         -0.00061417,  0.00043678],
        [ 0.00135803,  0.00086594,  0.00025940,  ...,  0.00056458,
         -0.00068665,  0.00035095],
        [ 0.00138092,  0.00082016,  0.00028038,  ...,  0.00056076,
         -0.00065231,  0.00032425]], dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 0.00343323,  0.00285339,  0.00128937,  ...,  0.00023365,
         -0.00445557, -0.00337219],
        [ 0.00317383,  0.00127411,  0.00122070,  ...,  0.00064087,
         -0.00306702, -0.00139618],
        [ 0.00247192,  0.00088120,  0.00091934,  ...,  0.00071716,
         -0.00253296, -0.00112915],
        ...,
        [ 0.00138855,  0.00093842,  0.00025368,  ...,  0.00053787,
         -0.00061417,  0.00043678],
        [ 0.00135803,  0.00086594,  0.00025940,  ...,  0.00056458,
         -0.00068665,  0.00035095],
        [ 0.00138092,  0.00082016,  0.00028038,  ...,  0.00056076,
         -0.00065231,  0.00032425]], dtype=torch.bfloat16)
================================================================================
model.layer[0].self_attn.qkv             CHECK_SUCCESS: False eq_num/sum: 30667/133120
============================================================
tensor([[-3.01003456e-06,  5.27501106e-06, -2.04145908e-06,  ...,
          2.33650208e-04, -4.45556641e-03, -3.37219238e-03],
        [ 1.88350677e-05, -3.76999378e-06, -1.77621841e-05,  ...,
          1.04522705e-03, -1.67083740e-03,  5.79833984e-04],
        [-1.37090683e-05,  1.64657831e-06,  1.86264515e-06,  ...,
          8.69750977e-04, -1.47247314e-03, -5.87463379e-04],
        ...,
        [ 1.09076500e-05,  1.49607658e-05, -2.28881836e-05,  ...,
          1.74713135e-03,  1.92260742e-03,  3.63159180e-03],
        [-1.37090683e-05,  1.64657831e-06,  1.86264515e-06,  ...,
          8.69750977e-04, -1.47247314e-03, -5.87463379e-04],
        [-3.95774841e-05,  5.03659248e-06,  2.32458115e-05,  ...,
          4.92095947e-04, -2.30789185e-04, -9.83476639e-06]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[-2.84612179e-06,  5.30481339e-06, -2.08616257e-06,  ...,
          2.30789185e-04, -4.42504883e-03, -3.37219238e-03],
        [ 1.89542770e-05, -3.79979610e-06, -1.77621841e-05,  ...,
          1.05285645e-03, -1.66320801e-03,  5.83648682e-04],
        [-1.37090683e-05,  1.67638063e-06,  1.92224979e-06,  ...,
          8.69750977e-04, -1.44958496e-03, -5.72204590e-04],
        ...,
        [ 1.06692314e-05,  1.49011612e-05, -2.30073929e-05,  ...,
          1.72424316e-03,  1.91497803e-03,  3.60107422e-03],
        [-1.37090683e-05,  1.67638063e-06,  1.92224979e-06,  ...,
          8.69750977e-04, -1.44958496e-03, -5.72204590e-04],
        [-3.95774841e-05,  5.00679016e-06,  2.33650208e-05,  ...,
          4.76837158e-04, -2.14576721e-04, -1.18017197e-05]],
       dtype=torch.bfloat16)
================================================================================
model.layer[1].input                     CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[ 0.01324463,  0.00787354, -0.03100586,  ...,  0.01367188,
         -0.00170898, -0.00463867],
        [ 0.00848389,  0.00637817, -0.02099609,  ...,  0.00738525,
         -0.00176239, -0.00033569],
        [ 0.01110840,  0.00314331, -0.01080322,  ...,  0.00631714,
         -0.00201416, -0.00166321],
        ...,
        [-0.00082779, -0.00064850, -0.00367737,  ..., -0.00109100,
          0.00068283, -0.00095749],
        [ 0.00128937,  0.00079727, -0.00113678,  ...,  0.00072861,
          0.00018024,  0.00010824],
        [ 0.00946045, -0.00311279,  0.01141357,  ..., -0.00212097,
         -0.00170898,  0.00176239]], dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 0.01324463,  0.00787354, -0.03100586,  ...,  0.01367188,
         -0.00170898, -0.00463867],
        [ 0.00848389,  0.00637817, -0.02099609,  ...,  0.00738525,
         -0.00176239, -0.00033569],
        [ 0.01110840,  0.00314331, -0.01080322,  ...,  0.00631714,
         -0.00201416, -0.00166321],
        ...,
        [-0.00082779, -0.00064850, -0.00367737,  ..., -0.00109100,
          0.00068283, -0.00095749],
        [ 0.00128937,  0.00079727, -0.00113678,  ...,  0.00072861,
          0.00018024,  0.00010824],
        [ 0.00946045, -0.00311279,  0.01141357,  ..., -0.00212097,
         -0.00170898,  0.00176239]], dtype=torch.bfloat16)
================================================================================
model.layer[1].input_norm                CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[ 7.78198242e-03,  6.21795654e-04, -5.19752502e-05,  ...,
         -3.63159180e-03,  7.24792480e-05, -2.39372253e-04],
        [ 2.82287598e-03,  7.13348389e-04, -5.48362732e-05,  ...,
         -7.01904297e-04,  3.64780426e-05, -1.65939331e-04],
        [ 2.02636719e-02, -4.71115112e-04,  0.00000000e+00,  ...,
         -1.12152100e-03,  4.05311584e-05, -1.37090683e-05],
        ...,
        [ 2.02941895e-03,  2.65121460e-04, -1.46031380e-05,  ...,
         -1.69372559e-03, -4.10079956e-05, -1.11579895e-04],
        [ 1.73339844e-02, -5.03540039e-04,  1.99079514e-05,  ...,
         -1.33514404e-04,  1.57356262e-05,  3.12328339e-05],
        [-4.73632812e-02, -5.95092773e-04,  3.60012054e-05,  ...,
          3.16619873e-04, -3.02791595e-05,  1.47819519e-05]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 7.78198242e-03,  6.21795654e-04, -5.19752502e-05,  ...,
         -3.63159180e-03,  7.24792480e-05, -2.39372253e-04],
        [ 2.82287598e-03,  7.13348389e-04, -5.48362732e-05,  ...,
         -7.01904297e-04,  3.64780426e-05, -1.65939331e-04],
        [ 2.02636719e-02, -4.71115112e-04,  0.00000000e+00,  ...,
         -1.12152100e-03,  4.05311584e-05, -1.37090683e-05],
        ...,
        [ 2.02941895e-03,  2.65121460e-04, -1.46031380e-05,  ...,
         -1.69372559e-03, -4.10079956e-05, -1.11579895e-04],
        [ 1.73339844e-02, -5.03540039e-04,  1.99079514e-05,  ...,
         -1.33514404e-04,  1.57356262e-05,  3.12328339e-05],
        [-4.73632812e-02, -5.95092773e-04,  3.60012054e-05,  ...,
          3.16619873e-04, -3.02791595e-05,  1.47819519e-05]],
       dtype=torch.bfloat16)
================================================================================
model.layer[1].input_residual            CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[ 0.01721191,  0.02600098, -0.01025391,  ...,  0.04272461,
          0.01049805, -0.03222656],
        [ 0.00244141,  0.03198242, -0.02185059,  ...,  0.00335693,
          0.00613403, -0.02490234],
        [ 0.04541016, -0.02148438,  0.01080322,  ...,  0.00616455,
          0.00552368,  0.00015259],
        ...,
        [ 0.00811768,  0.01385498, -0.00695801,  ...,  0.02514648,
         -0.00521851, -0.01483154],
        [ 0.04394531, -0.01904297,  0.01165771,  ...,  0.00064087,
          0.00107574,  0.00308228],
        [-0.11425781, -0.01513672,  0.00463867,  ..., -0.00065231,
         -0.00036240, -0.00047112]], dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 0.01721191,  0.02600098, -0.01025391,  ...,  0.04272461,
          0.01049805, -0.03222656],
        [ 0.00244141,  0.03198242, -0.02185059,  ...,  0.00335693,
          0.00613403, -0.02490234],
        [ 0.04541016, -0.02148438,  0.01080322,  ...,  0.00616455,
          0.00552368,  0.00015259],
        ...,
        [ 0.00811768,  0.01385498, -0.00695801,  ...,  0.02514648,
         -0.00521851, -0.01483154],
        [ 0.04394531, -0.01904297,  0.01165771,  ...,  0.00064087,
          0.00107574,  0.00308228],
        [-0.11425781, -0.01513672,  0.00463867,  ..., -0.00065231,
         -0.00036240, -0.00047112]], dtype=torch.bfloat16)
================================================================================
model.layer[1].mlp                       CHECK_SUCCESS: False eq_num/sum: 19535/106496
============================================================
tensor([[-0.02087402,  0.00866699, -0.05810547,  ...,  0.00411987,
          0.00521851, -0.00215149],
        [-0.00640869,  0.01141357, -0.03051758,  ...,  0.00491333,
         -0.00659180,  0.00225830],
        [-0.01916504, -0.00055695, -0.01782227,  ..., -0.00518799,
          0.00291443,  0.00430298],
        ...,
        [-0.02746582,  0.04150391, -0.04492188,  ...,  0.00329590,
          0.00811768,  0.00418091],
        [-0.00793457, -0.01055908, -0.02770996,  ..., -0.00037003,
          0.00224304,  0.00090408],
        [-0.00732422, -0.00759888, -0.03637695,  ..., -0.00634766,
         -0.00107574,  0.00373840]], dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[-0.02099609,  0.00878906, -0.05834961,  ...,  0.00399780,
          0.00534058, -0.00216675],
        [-0.00653076,  0.01147461, -0.03063965,  ...,  0.00479126,
         -0.00653076,  0.00225830],
        [-0.01904297, -0.00056839, -0.01782227,  ..., -0.00527954,
          0.00297546,  0.00430298],
        ...,
        [-0.02734375,  0.04150391, -0.04467773,  ...,  0.00343323,
          0.00817871,  0.00421143],
        [-0.00778198, -0.01062012, -0.02783203,  ..., -0.00047302,
          0.00225830,  0.00091934],
        [-0.00717163, -0.00765991, -0.03637695,  ..., -0.00640869,
         -0.00106049,  0.00378418]], dtype=torch.bfloat16)
================================================================================
model.layer[1].mlp.act_out               CHECK_SUCCESS: True eq_num/sum: 372736/372736
============================================================
tensor([[ 1.69677734e-02,  1.48925781e-02, -4.33349609e-03,  ...,
         -5.03540039e-04,  6.25610352e-04,  1.12503767e-06],
        [ 3.79943848e-03,  5.34057617e-03,  2.01416016e-03,  ...,
         -1.13010406e-04,  3.62396240e-04,  2.19345093e-05],
        [ 5.03540039e-03,  2.57873535e-03, -1.77764893e-03,  ...,
         -2.37464905e-04,  1.04427338e-04,  1.43051147e-05],
        ...,
        [ 8.31604004e-04,  7.93457031e-04,  6.71386719e-03,  ...,
         -2.44379044e-06, -2.07424164e-05,  3.31401825e-05],
        [ 9.11712646e-04, -3.31878662e-04, -9.34600830e-04,  ...,
         -4.95910645e-05,  5.28991222e-07,  3.67164612e-05],
        [ 1.67083740e-03,  4.60147858e-05,  1.50299072e-03,  ...,
          3.50952148e-04,  7.20024109e-05, -7.96318054e-05]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 1.69677734e-02,  1.48925781e-02, -4.33349609e-03,  ...,
         -5.03540039e-04,  6.25610352e-04,  1.12503767e-06],
        [ 3.79943848e-03,  5.34057617e-03,  2.01416016e-03,  ...,
         -1.13010406e-04,  3.62396240e-04,  2.19345093e-05],
        [ 5.03540039e-03,  2.57873535e-03, -1.77764893e-03,  ...,
         -2.37464905e-04,  1.04427338e-04,  1.43051147e-05],
        ...,
        [ 8.31604004e-04,  7.93457031e-04,  6.71386719e-03,  ...,
         -2.44379044e-06, -2.07424164e-05,  3.31401825e-05],
        [ 9.11712646e-04, -3.31878662e-04, -9.34600830e-04,  ...,
         -4.95910645e-05,  5.28991222e-07,  3.67164612e-05],
        [ 1.67083740e-03,  4.60147858e-05,  1.50299072e-03,  ...,
          3.50952148e-04,  7.20024109e-05, -7.96318054e-05]],
       dtype=torch.bfloat16)
================================================================================
model.layer[1].mlp.gate_up_out           CHECK_SUCCESS: False eq_num/sum: 147248/745472
============================================================
tensor([[ 1.82617188e-01,  2.04101562e-01,  1.94335938e-01,  ...,
         -1.33056641e-02,  1.19628906e-02,  5.26905060e-05],
        [ 8.49609375e-02,  1.22558594e-01,  1.22558594e-01,  ...,
         -9.39941406e-03,  1.14135742e-02,  3.49426270e-03],
        [ 1.05468750e-01,  1.15234375e-01,  1.18164062e-01,  ...,
         -2.12402344e-02,  6.59179688e-03,  2.80761719e-03],
        ...,
        [ 4.54101562e-02,  6.78710938e-02,  1.49414062e-01,  ...,
          5.41687012e-04,  3.57055664e-03,  8.36181641e-03],
        [ 5.10253906e-02,  3.03955078e-02,  6.88476562e-02,  ...,
         -1.27563477e-02, -1.08242035e-04,  4.27246094e-03],
        [ 6.39648438e-02,  5.12695312e-02,  1.12304688e-01,  ...,
         -1.57470703e-02, -3.12805176e-03,  3.46374512e-03]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 1.82617188e-01,  2.04101562e-01,  1.94335938e-01,  ...,
         -1.36108398e-02,  1.17797852e-02, -6.05583191e-05],
        [ 8.44726562e-02,  1.23535156e-01,  1.22070312e-01,  ...,
         -9.70458984e-03,  1.14746094e-02,  3.41796875e-03],
        [ 1.04492188e-01,  1.15722656e-01,  1.18164062e-01,  ...,
         -2.14843750e-02,  6.59179688e-03,  2.71606445e-03],
        ...,
        [ 4.51660156e-02,  6.73828125e-02,  1.49414062e-01,  ...,
          4.99725342e-04,  3.67736816e-03,  8.42285156e-03],
        [ 5.07812500e-02,  3.08837891e-02,  6.88476562e-02,  ...,
         -1.28784180e-02, -7.05718994e-05,  4.27246094e-03],
        [ 6.68945312e-02,  5.34667969e-02,  1.12792969e-01,  ...,
         -1.55639648e-02, -2.42614746e-03,  3.76892090e-03]],
       dtype=torch.bfloat16)
================================================================================
model.layer[1].post_norm                 CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[ 5.56945801e-04, -8.27789307e-04,  4.32968140e-04,  ...,
          9.37500000e-02,  3.23486328e-03, -1.85546875e-02],
        [-5.79833984e-04, -1.25122070e-03,  4.48226929e-04,  ...,
          2.05078125e-02, -3.21960449e-03, -1.47094727e-02],
        [ 4.18090820e-03,  1.70898438e-03, -5.57899475e-05,  ...,
          2.80761719e-02, -2.94494629e-03, -2.59399414e-03],
        ...,
        [-1.58309937e-04, -4.00543213e-04,  9.15527344e-05,  ...,
          4.39453125e-02, -7.75146484e-03, -9.70458984e-03],
        [ 4.27246094e-03,  1.71661377e-03, -1.69754028e-04,  ...,
          2.91442871e-03, -3.86047363e-03,  2.07519531e-03],
        [-1.55639648e-02,  1.95312500e-03, -2.91824341e-04,  ...,
         -9.52148438e-03, -8.97216797e-03,  1.11389160e-03]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 5.56945801e-04, -8.27789307e-04,  4.32968140e-04,  ...,
          9.37500000e-02,  3.23486328e-03, -1.85546875e-02],
        [-5.79833984e-04, -1.25122070e-03,  4.48226929e-04,  ...,
          2.05078125e-02, -3.21960449e-03, -1.47094727e-02],
        [ 4.18090820e-03,  1.70898438e-03, -5.57899475e-05,  ...,
          2.80761719e-02, -2.94494629e-03, -2.59399414e-03],
        ...,
        [-1.58309937e-04, -4.00543213e-04,  9.15527344e-05,  ...,
          4.39453125e-02, -7.75146484e-03, -9.70458984e-03],
        [ 4.27246094e-03,  1.71661377e-03, -1.69754028e-04,  ...,
          2.91442871e-03, -3.86047363e-03,  2.07519531e-03],
        [-1.55639648e-02,  1.95312500e-03, -2.91824341e-04,  ...,
         -9.52148438e-03, -8.97216797e-03,  1.11389160e-03]],
       dtype=torch.bfloat16)
================================================================================
model.layer[1].post_norm_residual        CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[ 0.00720215,  0.01721191, -0.05004883,  ...,  0.05786133,
          0.00448608, -0.03564453],
        [-0.00726318,  0.02514648, -0.05004883,  ...,  0.01220703,
         -0.00430298, -0.02722168],
        [ 0.03857422, -0.02526855,  0.00457764,  ...,  0.01226807,
         -0.00289917, -0.00352478],
        ...,
        [-0.00180054,  0.00732422, -0.00927734,  ...,  0.02380371,
         -0.00946045, -0.01635742],
        [ 0.03564453, -0.02307129,  0.01263428,  ...,  0.00115967,
         -0.00344849,  0.00256348],
        [-0.11083984, -0.02233887,  0.01843262,  ..., -0.00321960,
         -0.00683594,  0.00117493]], dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 0.00720215,  0.01721191, -0.05004883,  ...,  0.05786133,
          0.00448608, -0.03564453],
        [-0.00726318,  0.02514648, -0.05004883,  ...,  0.01220703,
         -0.00430298, -0.02722168],
        [ 0.03857422, -0.02526855,  0.00457764,  ...,  0.01226807,
         -0.00289917, -0.00352478],
        ...,
        [-0.00180054,  0.00732422, -0.00927734,  ...,  0.02380371,
         -0.00946045, -0.01635742],
        [ 0.03564453, -0.02307129,  0.01263428,  ...,  0.00115967,
         -0.00344849,  0.00256348],
        [-0.11083984, -0.02233887,  0.01843262,  ..., -0.00321960,
         -0.00683594,  0.00117493]], dtype=torch.bfloat16)
================================================================================
model.layer[1].residual_norm             CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[ 0.03051758,  0.03393555, -0.04125977,  ...,  0.05639648,
          0.00878906, -0.03686523],
        [ 0.01092529,  0.03833008, -0.04296875,  ...,  0.01074219,
          0.00436401, -0.02526855],
        [ 0.05664062, -0.01831055,  0.00000000,  ...,  0.01245117,
          0.00350952, -0.00151062],
        ...,
        [ 0.00729370,  0.01318359, -0.01062012,  ...,  0.02404785,
         -0.00454712, -0.01574707],
        [ 0.04516602, -0.01818848,  0.01049805,  ...,  0.00137329,
          0.00125885,  0.00318909],
        [-0.10498047, -0.01831055,  0.01611328,  ..., -0.00277710,
         -0.00207520,  0.00128937]], dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 0.03051758,  0.03393555, -0.04125977,  ...,  0.05639648,
          0.00878906, -0.03686523],
        [ 0.01092529,  0.03833008, -0.04296875,  ...,  0.01074219,
          0.00436401, -0.02526855],
        [ 0.05664062, -0.01831055,  0.00000000,  ...,  0.01245117,
          0.00350952, -0.00151062],
        ...,
        [ 0.00729370,  0.01318359, -0.01062012,  ...,  0.02404785,
         -0.00454712, -0.01574707],
        [ 0.04516602, -0.01818848,  0.01049805,  ...,  0.00137329,
          0.00125885,  0.00318909],
        [-0.10498047, -0.01831055,  0.01611328,  ..., -0.00277710,
         -0.00207520,  0.00128937]], dtype=torch.bfloat16)
================================================================================
model.layer[1].self_attn                 CHECK_SUCCESS: False eq_num/sum: 30689/106496
============================================================
tensor([[-0.02331543, -0.01672363, -0.00878906,  ...,  0.00143433,
         -0.00430298,  0.00117493],
        [-0.01818848, -0.01312256, -0.00701904,  ...,  0.00144196,
         -0.00866699, -0.00196838],
        [-0.01794434, -0.00692749,  0.00457764,  ..., -0.00020027,
         -0.00640869, -0.00201416],
        ...,
        [-0.00909424, -0.00585938,  0.00135040,  ..., -0.00028419,
         -0.00491333, -0.00056076],
        [-0.00958252, -0.00485229,  0.00215149,  ..., -0.00021744,
         -0.00469971, -0.00062180],
        [-0.00607300, -0.00405884,  0.00230408,  ..., -0.00044632,
         -0.00476074, -0.00011444]], dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[-0.02307129, -0.01672363, -0.00885010,  ...,  0.00143433,
         -0.00430298,  0.00119781],
        [-0.01806641, -0.01312256, -0.00708008,  ...,  0.00142670,
         -0.00866699, -0.00194550],
        [-0.01794434, -0.00695801,  0.00445557,  ..., -0.00020981,
         -0.00640869, -0.00199890],
        ...,
        [-0.00903320, -0.00582886,  0.00130463,  ..., -0.00029945,
         -0.00491333, -0.00055313],
        [-0.00952148, -0.00482178,  0.00209045,  ..., -0.00022984,
         -0.00469971, -0.00061417],
        [-0.00604248, -0.00408936,  0.00224304,  ..., -0.00045776,
         -0.00476074, -0.00010824]], dtype=torch.bfloat16)
================================================================================
model.layer[1].self_attn.attn_out        CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[ 1.25885010e-03, -1.34277344e-03,  4.55856323e-04,  ...,
          4.13894653e-04, -1.80053711e-03, -9.76562500e-04],
        [ 1.83105469e-03, -2.47192383e-03,  6.90460205e-04,  ...,
          1.39617920e-03,  8.39233398e-05, -6.40869141e-04],
        [ 1.30462646e-03, -1.60980225e-03,  7.62939453e-04,  ...,
          9.91821289e-04,  8.01086426e-05, -6.21795654e-04],
        ...,
        [ 1.32751465e-03, -7.62939453e-04,  5.68389893e-04,  ...,
          5.11169434e-04,  7.51495361e-04, -4.95910645e-04],
        [ 1.26647949e-03, -6.63757324e-04,  5.98907471e-04,  ...,
          4.61578369e-04,  7.13348389e-04, -5.14984131e-04],
        [ 1.19018555e-03, -5.56945801e-04,  5.83648682e-04,  ...,
          3.03268433e-04,  7.36236572e-04, -4.99725342e-04]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 1.25885010e-03, -1.34277344e-03,  4.55856323e-04,  ...,
          4.13894653e-04, -1.80053711e-03, -9.76562500e-04],
        [ 1.83105469e-03, -2.47192383e-03,  6.90460205e-04,  ...,
          1.39617920e-03,  8.39233398e-05, -6.40869141e-04],
        [ 1.30462646e-03, -1.60980225e-03,  7.62939453e-04,  ...,
          9.91821289e-04,  8.01086426e-05, -6.21795654e-04],
        ...,
        [ 1.32751465e-03, -7.62939453e-04,  5.68389893e-04,  ...,
          5.11169434e-04,  7.51495361e-04, -4.95910645e-04],
        [ 1.26647949e-03, -6.63757324e-04,  5.98907471e-04,  ...,
          4.61578369e-04,  7.13348389e-04, -5.14984131e-04],
        [ 1.19018555e-03, -5.56945801e-04,  5.83648682e-04,  ...,
          3.03268433e-04,  7.36236572e-04, -4.99725342e-04]],
       dtype=torch.bfloat16)
================================================================================
model.layer[1].self_attn.qkv             CHECK_SUCCESS: False eq_num/sum: 36030/133120
============================================================
tensor([[-9.53674316e-07, -1.28895044e-06, -1.19954348e-06,  ...,
          4.13894653e-04, -1.80053711e-03, -9.76562500e-04],
        [-2.32458115e-06,  3.96370888e-06,  5.30481339e-06,  ...,
          2.38037109e-03,  1.96838379e-03, -3.01361084e-04],
        [-1.81794167e-06, -1.08480453e-05, -9.89437103e-06,  ...,
          1.89781189e-04,  7.29560852e-05, -5.87463379e-04],
        ...,
        [ 4.67523932e-07,  7.48038292e-06,  8.46385956e-06,  ...,
         -3.58581543e-04,  3.35693359e-03, -3.54766846e-04],
        [-1.26659870e-06, -6.91413879e-06, -6.52670860e-06,  ...,
         -7.86781311e-05,  2.86102295e-04, -7.01904297e-04],
        [-3.57627869e-07, -1.81198120e-05, -1.64508820e-05,  ...,
         -1.59454346e-03,  9.99450684e-04, -3.12805176e-04]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[-9.61124897e-07, -1.28149986e-06, -1.19954348e-06,  ...,
          4.19616699e-04, -1.80053711e-03, -9.61303711e-04],
        [-2.35438347e-06,  3.96370888e-06,  5.33461571e-06,  ...,
          2.38037109e-03,  1.98364258e-03, -2.95639038e-04],
        [-1.80304050e-06, -1.08480453e-05, -9.83476639e-06,  ...,
          2.07901001e-04,  4.93526459e-05, -5.87463379e-04],
        ...,
        [ 4.41446900e-07,  7.51018524e-06,  8.46385956e-06,  ...,
         -3.64303589e-04,  3.35693359e-03, -3.54766846e-04],
        [-1.25914812e-06, -6.88433647e-06, -6.52670860e-06,  ...,
         -6.29425049e-05,  2.70843506e-04, -7.05718994e-04],
        [-3.42726707e-07, -1.80006027e-05, -1.64508820e-05,  ...,
         -1.58691406e-03,  9.72747803e-04, -3.29971313e-04]],
       dtype=torch.bfloat16)
================================================================================
model.layer[2].input                     CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[-0.02087402,  0.00866699, -0.05810547,  ...,  0.00411987,
          0.00521851, -0.00215149],
        [-0.00640869,  0.01141357, -0.03051758,  ...,  0.00491333,
         -0.00659180,  0.00225830],
        [-0.01916504, -0.00055695, -0.01782227,  ..., -0.00518799,
          0.00291443,  0.00430298],
        ...,
        [-0.02746582,  0.04150391, -0.04492188,  ...,  0.00329590,
          0.00811768,  0.00418091],
        [-0.00793457, -0.01055908, -0.02770996,  ..., -0.00037003,
          0.00224304,  0.00090408],
        [-0.00732422, -0.00759888, -0.03637695,  ..., -0.00634766,
         -0.00107574,  0.00373840]], dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[-0.02087402,  0.00866699, -0.05810547,  ...,  0.00411987,
          0.00521851, -0.00215149],
        [-0.00640869,  0.01141357, -0.03051758,  ...,  0.00491333,
         -0.00659180,  0.00225830],
        [-0.01916504, -0.00055695, -0.01782227,  ..., -0.00518799,
          0.00291443,  0.00430298],
        ...,
        [-0.02746582,  0.04150391, -0.04492188,  ...,  0.00329590,
          0.00811768,  0.00418091],
        [-0.00793457, -0.01055908, -0.02770996,  ..., -0.00037003,
          0.00224304,  0.00090408],
        [-0.00732422, -0.00759888, -0.03637695,  ..., -0.00634766,
         -0.00107574,  0.00373840]], dtype=torch.bfloat16)
================================================================================
model.layer[2].input_norm                CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[-6.98242188e-02,  4.08935547e-03, -1.59179688e-01,  ...,
          5.18798828e-04, -2.33650208e-04, -6.52313232e-04],
        [-9.03320312e-02,  7.50732422e-03, -1.53320312e-01,  ...,
          1.85966492e-04,  3.39508057e-04, -5.56945801e-04],
        [ 1.66015625e-01, -6.86645508e-03, -3.24707031e-02,  ...,
          9.96589661e-05, -6.14672899e-07,  2.24113464e-05],
        ...,
        [-2.31445312e-01,  1.19628906e-02, -1.23535156e-01,  ...,
          3.52859497e-04,  5.03063202e-05, -3.26156616e-04],
        [ 2.61718750e-01, -9.88769531e-03, -4.10156250e-02,  ...,
          1.22785568e-05,  5.38825989e-05,  1.10626221e-04],
        [-8.94531250e-01, -7.01904297e-03, -3.90625000e-02,  ...,
         -1.19209290e-04,  2.84194946e-04,  1.25885010e-04]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[-6.98242188e-02,  4.08935547e-03, -1.59179688e-01,  ...,
          5.18798828e-04, -2.33650208e-04, -6.52313232e-04],
        [-9.03320312e-02,  7.50732422e-03, -1.53320312e-01,  ...,
          1.85966492e-04,  3.39508057e-04, -5.56945801e-04],
        [ 1.66015625e-01, -6.86645508e-03, -3.24707031e-02,  ...,
          9.96589661e-05, -6.14672899e-07,  2.24113464e-05],
        ...,
        [-2.31445312e-01,  1.19628906e-02, -1.23535156e-01,  ...,
          3.52859497e-04,  5.03063202e-05, -3.26156616e-04],
        [ 2.61718750e-01, -9.88769531e-03, -4.10156250e-02,  ...,
          1.22785568e-05,  5.38825989e-05,  1.10626221e-04],
        [-8.94531250e-01, -7.01904297e-03, -3.90625000e-02,  ...,
         -1.19209290e-04,  2.84194946e-04,  1.25885010e-04]],
       dtype=torch.bfloat16)
================================================================================
model.layer[2].input_residual            CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[ 0.00720215,  0.01721191, -0.05004883,  ...,  0.05786133,
          0.00448608, -0.03564453],
        [-0.00726318,  0.02514648, -0.05004883,  ...,  0.01220703,
         -0.00430298, -0.02722168],
        [ 0.03857422, -0.02526855,  0.00457764,  ...,  0.01226807,
         -0.00289917, -0.00352478],
        ...,
        [-0.00180054,  0.00732422, -0.00927734,  ...,  0.02380371,
         -0.00946045, -0.01635742],
        [ 0.03564453, -0.02307129,  0.01263428,  ...,  0.00115967,
         -0.00344849,  0.00256348],
        [-0.11083984, -0.02233887,  0.01843262,  ..., -0.00321960,
         -0.00683594,  0.00117493]], dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 0.00720215,  0.01721191, -0.05004883,  ...,  0.05786133,
          0.00448608, -0.03564453],
        [-0.00726318,  0.02514648, -0.05004883,  ...,  0.01220703,
         -0.00430298, -0.02722168],
        [ 0.03857422, -0.02526855,  0.00457764,  ...,  0.01226807,
         -0.00289917, -0.00352478],
        ...,
        [-0.00180054,  0.00732422, -0.00927734,  ...,  0.02380371,
         -0.00946045, -0.01635742],
        [ 0.03564453, -0.02307129,  0.01263428,  ...,  0.00115967,
         -0.00344849,  0.00256348],
        [-0.11083984, -0.02233887,  0.01843262,  ..., -0.00321960,
         -0.00683594,  0.00117493]], dtype=torch.bfloat16)
================================================================================
model.layer[2].mlp                       CHECK_SUCCESS: False eq_num/sum: 24526/106496
============================================================
tensor([[ 0.00994873, -0.00138092,  0.05468750,  ..., -0.01098633,
          0.00531006, -0.00460815],
        [-0.00389099,  0.00119019,  0.03735352,  ..., -0.00049591,
         -0.00215149,  0.00549316],
        [ 0.00325012, -0.00555420, -0.00201416,  ...,  0.00058746,
          0.00042915,  0.00055313],
        ...,
        [ 0.00830078,  0.01293945, -0.02136230,  ..., -0.00527954,
         -0.00033379,  0.00215149],
        [ 0.01269531, -0.00485229, -0.01208496,  ...,  0.00276184,
          0.00129700, -0.00075912],
        [-0.00157166,  0.00032806,  0.00033188,  ...,  0.00321960,
          0.00121307, -0.00067902]], dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 0.01007080, -0.00141144,  0.05493164,  ..., -0.01092529,
          0.00537109, -0.00457764],
        [-0.00381470,  0.00111389,  0.03759766,  ..., -0.00043488,
         -0.00212097,  0.00543213],
        [ 0.00329590, -0.00552368, -0.00201416,  ...,  0.00053024,
          0.00045013,  0.00053024],
        ...,
        [ 0.00817871,  0.01281738, -0.02148438,  ..., -0.00521851,
         -0.00028419,  0.00218201],
        [ 0.01275635, -0.00485229, -0.01208496,  ...,  0.00268555,
          0.00131989, -0.00078201],
        [-0.00153351,  0.00030708,  0.00032234,  ...,  0.00321960,
          0.00123596, -0.00068283]], dtype=torch.bfloat16)
================================================================================
model.layer[2].mlp.act_out               CHECK_SUCCESS: True eq_num/sum: 372736/372736
============================================================
tensor([[ 1.45912170e-04,  3.69262695e-03,  7.69042969e-03,  ...,
          8.46385956e-06,  6.14672899e-08,  3.43322754e-05],
        [-3.05175781e-04,  1.41143799e-03,  7.93457031e-03,  ...,
         -6.34193420e-05, -2.93254852e-05,  7.09295273e-06],
        [ 7.47680664e-04,  4.50134277e-04, -2.22206116e-04,  ...,
          6.49690628e-06,  1.42455101e-05,  7.09295273e-06],
        ...,
        [-9.59634781e-06,  3.11279297e-03,  2.16796875e-01,  ...,
          7.70568848e-04, -1.20401382e-05, -1.83582306e-05],
        [ 7.97271729e-04,  1.76239014e-03,  3.11279297e-03,  ...,
          6.48498535e-05,  5.79357147e-05, -2.63452530e-05],
        [ 1.03759766e-03,  1.42669678e-03,  1.33056641e-02,  ...,
          2.59876251e-05,  3.60012054e-05, -3.29017639e-05]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 1.45912170e-04,  3.69262695e-03,  7.69042969e-03,  ...,
          8.46385956e-06,  6.14672899e-08,  3.43322754e-05],
        [-3.05175781e-04,  1.41143799e-03,  7.93457031e-03,  ...,
         -6.34193420e-05, -2.93254852e-05,  7.09295273e-06],
        [ 7.47680664e-04,  4.50134277e-04, -2.22206116e-04,  ...,
          6.49690628e-06,  1.42455101e-05,  7.09295273e-06],
        ...,
        [-9.59634781e-06,  3.11279297e-03,  2.16796875e-01,  ...,
          7.70568848e-04, -1.20401382e-05, -1.83582306e-05],
        [ 7.97271729e-04,  1.76239014e-03,  3.11279297e-03,  ...,
          6.48498535e-05,  5.79357147e-05, -2.63452530e-05],
        [ 1.03759766e-03,  1.42669678e-03,  1.33056641e-02,  ...,
          2.59876251e-05,  3.60012054e-05, -3.29017639e-05]],
       dtype=torch.bfloat16)
================================================================================
model.layer[2].mlp.gate_up_out           CHECK_SUCCESS: False eq_num/sum: 182385/745472
============================================================
tensor([[ 2.31933594e-02,  9.37500000e-02, -1.50390625e-01,  ...,
         -1.61132812e-02,  8.58306885e-04, -9.94873047e-03],
        [-4.10156250e-02,  5.51757812e-02, -2.10937500e-01,  ...,
         -1.28784180e-02, -3.25012207e-03, -6.19506836e-03],
        [-6.44531250e-02, -2.91748047e-02,  5.37109375e-02,  ...,
          4.99725342e-04,  8.05664062e-03, -9.70458984e-03],
        ...,
        [-3.72314453e-03,  1.01074219e-01, -2.07812500e+00,  ...,
          1.84326172e-02, -1.61743164e-03, -7.26318359e-03],
        [-5.02929688e-02, -5.90820312e-02,  1.78710938e-01,  ...,
          3.90625000e-03,  7.29370117e-03, -8.17871094e-03],
        [-4.88281250e-02, -5.56640625e-02,  3.16406250e-01,  ...,
          2.97546387e-03,  7.56835938e-03, -7.41577148e-03]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 2.27050781e-02,  9.42382812e-02, -1.50390625e-01,  ...,
         -1.61132812e-02,  9.19342041e-04, -9.94873047e-03],
        [-4.17480469e-02,  5.56640625e-02, -2.10937500e-01,  ...,
         -1.27563477e-02, -3.20434570e-03, -6.13403320e-03],
        [-6.49414062e-02, -2.92968750e-02,  5.39550781e-02,  ...,
          4.99725342e-04,  7.99560547e-03, -9.76562500e-03],
        ...,
        [-4.05883789e-03,  1.00097656e-01, -2.07812500e+00,  ...,
          1.83105469e-02, -1.69372559e-03, -7.17163086e-03],
        [-5.02929688e-02, -5.95703125e-02,  1.77734375e-01,  ...,
          3.90625000e-03,  7.17163086e-03, -8.23974609e-03],
        [-4.88281250e-02, -5.54199219e-02,  3.16406250e-01,  ...,
          2.99072266e-03,  7.44628906e-03, -7.47680664e-03]],
       dtype=torch.bfloat16)
================================================================================
model.layer[2].post_norm                 CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[ 2.06298828e-02,  1.57470703e-02, -3.51562500e-01,  ...,
          1.01074219e-01,  5.55419922e-03, -1.00708008e-02],
        [ 1.17187500e-02,  3.75976562e-02, -2.94921875e-01,  ...,
          3.11279297e-02, -9.33837891e-03, -1.02539062e-02],
        [-3.29589844e-02, -3.61328125e-02,  8.69140625e-02,  ...,
          2.03857422e-02, -3.05175781e-04, -2.89916992e-04],
        ...,
        [ 7.42187500e-02,  6.00585938e-02, -1.44531250e-01,  ...,
          8.00781250e-02, -7.82012939e-04, -4.97436523e-03],
        [-3.41796875e-02, -4.10156250e-02,  1.25976562e-01,  ...,
         -3.32641602e-03, -7.85827637e-04,  2.34985352e-03],
        [ 2.63671875e-01, -2.23388672e-02,  1.04980469e-01,  ...,
         -2.89306641e-02, -4.85229492e-03,  2.73132324e-03]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 2.06298828e-02,  1.57470703e-02, -3.51562500e-01,  ...,
          1.01074219e-01,  5.55419922e-03, -1.00708008e-02],
        [ 1.17187500e-02,  3.75976562e-02, -2.94921875e-01,  ...,
          3.11279297e-02, -9.33837891e-03, -1.02539062e-02],
        [-3.29589844e-02, -3.61328125e-02,  8.69140625e-02,  ...,
          2.03857422e-02, -3.05175781e-04, -2.89916992e-04],
        ...,
        [ 7.42187500e-02,  6.00585938e-02, -1.44531250e-01,  ...,
          8.00781250e-02, -7.82012939e-04, -4.97436523e-03],
        [-3.41796875e-02, -4.10156250e-02,  1.25976562e-01,  ...,
         -3.32641602e-03, -7.85827637e-04,  2.34985352e-03],
        [ 2.63671875e-01, -2.23388672e-02,  1.04980469e-01,  ...,
         -2.89306641e-02, -4.85229492e-03,  2.73132324e-03]],
       dtype=torch.bfloat16)
================================================================================
model.layer[2].post_norm_residual        CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[-0.01275635,  0.01428223, -0.08642578,  ...,  0.05688477,
          0.01196289, -0.03369141],
        [-0.00573730,  0.02685547, -0.05712891,  ...,  0.01385498,
         -0.01586914, -0.02697754],
        [ 0.01342773, -0.02148438,  0.01397705,  ...,  0.00753784,
         -0.00043106, -0.00063324],
        ...,
        [-0.03100586,  0.03662109, -0.02380371,  ...,  0.03039551,
         -0.00113678, -0.01116943],
        [ 0.01251221, -0.02197266,  0.01831055,  ..., -0.00111389,
         -0.00100708,  0.00463867],
        [-0.11865234, -0.01470947,  0.01867676,  ..., -0.01184082,
         -0.00759888,  0.00662231]], dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[-0.01275635,  0.01428223, -0.08642578,  ...,  0.05688477,
          0.01196289, -0.03369141],
        [-0.00573730,  0.02685547, -0.05712891,  ...,  0.01385498,
         -0.01586914, -0.02697754],
        [ 0.01342773, -0.02148438,  0.01397705,  ...,  0.00753784,
         -0.00043106, -0.00063324],
        ...,
        [-0.03100586,  0.03662109, -0.02380371,  ...,  0.03039551,
         -0.00113678, -0.01116943],
        [ 0.01251221, -0.02197266,  0.01831055,  ..., -0.00111389,
         -0.00100708,  0.00463867],
        [-0.11865234, -0.01470947,  0.01867676,  ..., -0.01184082,
         -0.00759888,  0.00662231]], dtype=torch.bfloat16)
================================================================================
model.layer[2].residual_norm             CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[-1.36718750e-02,  2.58789062e-02, -1.08398438e-01,  ...,
          6.20117188e-02,  9.70458984e-03, -3.78417969e-02],
        [-1.36718750e-02,  3.66210938e-02, -8.05664062e-02,  ...,
          1.70898438e-02, -1.08642578e-02, -2.49023438e-02],
        [ 1.94091797e-02, -2.58789062e-02, -1.32446289e-02,  ...,
          7.08007812e-03,  1.52587891e-05,  7.78198242e-04],
        ...,
        [-2.92968750e-02,  4.88281250e-02, -5.41992188e-02,  ...,
          2.70996094e-02, -1.34277344e-03, -1.22070312e-02],
        [ 2.77099609e-02, -3.36914062e-02, -1.50756836e-02,  ...,
          7.89642334e-04, -1.20544434e-03,  3.46374512e-03],
        [-1.18164062e-01, -2.99072266e-02, -1.79443359e-02,  ...,
         -9.58251953e-03, -7.93457031e-03,  4.91333008e-03]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[-1.36718750e-02,  2.58789062e-02, -1.08398438e-01,  ...,
          6.20117188e-02,  9.70458984e-03, -3.78417969e-02],
        [-1.36718750e-02,  3.66210938e-02, -8.05664062e-02,  ...,
          1.70898438e-02, -1.08642578e-02, -2.49023438e-02],
        [ 1.94091797e-02, -2.58789062e-02, -1.32446289e-02,  ...,
          7.08007812e-03,  1.52587891e-05,  7.78198242e-04],
        ...,
        [-2.92968750e-02,  4.88281250e-02, -5.41992188e-02,  ...,
          2.70996094e-02, -1.34277344e-03, -1.22070312e-02],
        [ 2.77099609e-02, -3.36914062e-02, -1.50756836e-02,  ...,
          7.89642334e-04, -1.20544434e-03,  3.46374512e-03],
        [-1.18164062e-01, -2.99072266e-02, -1.79443359e-02,  ...,
         -9.58251953e-03, -7.93457031e-03,  4.91333008e-03]],
       dtype=torch.bfloat16)
================================================================================
model.layer[2].self_attn                 CHECK_SUCCESS: False eq_num/sum: 37516/106496
============================================================
tensor([[ 0.00090790, -0.01159668,  0.02185059,  ..., -0.00503540,
          0.00228882,  0.00427246],
        [ 0.00793457, -0.00976562,  0.02343750,  ..., -0.00323486,
         -0.00503540, -0.00205994],
        [-0.00598145,  0.00445557,  0.02722168,  ...,  0.00044441,
         -0.00044632, -0.00141144],
        ...,
        [-0.00171661, -0.01232910,  0.03039551,  ...,  0.00325012,
          0.00020695,  0.00106049],
        [-0.01519775,  0.01165771,  0.03344727,  ..., -0.00190735,
          0.00019646,  0.00119019],
        [-0.00053787,  0.01519775,  0.03662109,  ..., -0.00222778,
          0.00033379,  0.00171661]], dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 0.00081635, -0.01153564,  0.02185059,  ..., -0.00503540,
          0.00231934,  0.00424194],
        [ 0.00781250, -0.00976562,  0.02355957,  ..., -0.00320435,
         -0.00500488, -0.00209045],
        [-0.00607300,  0.00445557,  0.02722168,  ...,  0.00047684,
         -0.00041962, -0.00141907],
        ...,
        [-0.00175476, -0.01232910,  0.03039551,  ...,  0.00326538,
          0.00022316,  0.00105286],
        [-0.01519775,  0.01165771,  0.03344727,  ..., -0.00191498,
          0.00021362,  0.00117493],
        [-0.00056839,  0.01519775,  0.03662109,  ..., -0.00221252,
          0.00034714,  0.00170898]], dtype=torch.bfloat16)
================================================================================
model.layer[2].self_attn.attn_out        CHECK_SUCCESS: False eq_num/sum: 45118/106496
============================================================
tensor([[-1.52587891e-04,  7.47680664e-04,  2.82526016e-05,  ...,
         -1.13677979e-03,  1.20544434e-03, -1.08337402e-03],
        [ 4.65393066e-04,  8.88824463e-04, -1.87873840e-04,  ...,
         -5.03540039e-04,  9.91821289e-04, -9.91821289e-04],
        [ 4.61578369e-04,  6.75201416e-04, -2.05039978e-04,  ...,
         -1.12152100e-03,  8.58306885e-04, -7.01904297e-04],
        ...,
        [ 2.19345093e-04,  3.66210938e-04,  4.92095947e-04,  ...,
         -7.36236572e-04,  3.47137451e-04, -2.67028809e-04],
        [ 2.34603882e-04,  3.54766846e-04,  4.53948975e-04,  ...,
         -7.55310059e-04,  4.02450562e-04, -2.72750854e-04],
        [ 2.16484070e-04,  4.32968140e-04,  4.78744507e-04,  ...,
         -8.92639160e-04,  3.66210938e-04, -8.15391541e-05]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[-1.52587891e-04,  7.47680664e-04,  2.82526016e-05,  ...,
         -1.13677979e-03,  1.20544434e-03, -1.08337402e-03],
        [ 4.65393066e-04,  8.88824463e-04, -1.87873840e-04,  ...,
         -5.03540039e-04,  9.91821289e-04, -9.91821289e-04],
        [ 4.61578369e-04,  6.79016113e-04, -2.05039978e-04,  ...,
         -1.12152100e-03,  8.62121582e-04, -7.01904297e-04],
        ...,
        [ 2.19345093e-04,  3.66210938e-04,  4.92095947e-04,  ...,
         -7.36236572e-04,  3.47137451e-04, -2.65121460e-04],
        [ 2.33650208e-04,  3.52859497e-04,  4.53948975e-04,  ...,
         -7.51495361e-04,  4.02450562e-04, -2.74658203e-04],
        [ 2.16484070e-04,  4.32968140e-04,  4.78744507e-04,  ...,
         -8.88824463e-04,  3.66210938e-04, -8.34465027e-05]],
       dtype=torch.bfloat16)
================================================================================
model.layer[2].self_attn.qkv             CHECK_SUCCESS: False eq_num/sum: 76574/133120
============================================================
tensor([[ 2.78472900e-04,  4.46319580e-04, -2.04086304e-04,  ...,
         -1.13677979e-03,  1.20544434e-03, -1.08337402e-03],
        [ 1.09100342e-03,  1.80816650e-03, -9.19342041e-04,  ...,
          1.28746033e-04,  7.78198242e-04, -9.04083252e-04],
        [-3.78417969e-03, -6.22558594e-03,  3.18908691e-03,  ...,
         -2.36511230e-03,  5.95092773e-04, -1.13964081e-04],
        ...,
        [ 4.54711914e-03,  7.41577148e-03, -3.76892090e-03,  ...,
          1.87683105e-03,  8.69750977e-04, -1.86157227e-03],
        [-3.38745117e-03, -5.43212891e-03,  2.79235840e-03,  ...,
         -1.06048584e-03,  1.00708008e-03, -2.82287598e-04],
        [-1.86157227e-03, -3.89099121e-03,  1.96838379e-03,  ...,
         -2.53295898e-03, -5.26905060e-05,  2.21252441e-03]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 2.80380249e-04,  4.52041626e-04, -2.06947327e-04,  ...,
         -1.19781494e-03,  1.20544434e-03, -1.09100342e-03],
        [ 1.09100342e-03,  1.80816650e-03, -9.19342041e-04,  ...,
          9.82284546e-05,  7.85827637e-04, -9.00268555e-04],
        [-3.78417969e-03, -6.19506836e-03,  3.17382812e-03,  ...,
         -2.50244141e-03,  5.03540039e-04, -1.64031982e-04],
        ...,
        [ 4.54711914e-03,  7.41577148e-03, -3.76892090e-03,  ...,
          1.95312500e-03,  9.99450684e-04, -1.82342529e-03],
        [-3.40270996e-03, -5.43212891e-03,  2.79235840e-03,  ...,
         -1.14440918e-03,  9.15527344e-04, -3.31878662e-04],
        [-1.84631348e-03, -3.89099121e-03,  1.96838379e-03,  ...,
         -2.76184082e-03, -1.29699707e-04,  2.24304199e-03]],
       dtype=torch.bfloat16)
================================================================================
model.layer[3].input                     CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[ 0.00994873, -0.00138092,  0.05468750,  ..., -0.01098633,
          0.00531006, -0.00460815],
        [-0.00389099,  0.00119019,  0.03735352,  ..., -0.00049591,
         -0.00215149,  0.00549316],
        [ 0.00325012, -0.00555420, -0.00201416,  ...,  0.00058746,
          0.00042915,  0.00055313],
        ...,
        [ 0.00830078,  0.01293945, -0.02136230,  ..., -0.00527954,
         -0.00033379,  0.00215149],
        [ 0.01269531, -0.00485229, -0.01208496,  ...,  0.00276184,
          0.00129700, -0.00075912],
        [-0.00157166,  0.00032806,  0.00033188,  ...,  0.00321960,
          0.00121307, -0.00067902]], dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 0.00994873, -0.00138092,  0.05468750,  ..., -0.01098633,
          0.00531006, -0.00460815],
        [-0.00389099,  0.00119019,  0.03735352,  ..., -0.00049591,
         -0.00215149,  0.00549316],
        [ 0.00325012, -0.00555420, -0.00201416,  ...,  0.00058746,
          0.00042915,  0.00055313],
        ...,
        [ 0.00830078,  0.01293945, -0.02136230,  ..., -0.00527954,
         -0.00033379,  0.00215149],
        [ 0.01269531, -0.00485229, -0.01208496,  ...,  0.00276184,
          0.00129700, -0.00075912],
        [-0.00157166,  0.00032806,  0.00033188,  ...,  0.00321960,
          0.00121307, -0.00067902]], dtype=torch.bfloat16)
================================================================================
model.layer[3].input_norm                CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[-2.66113281e-02,  7.20214844e-03, -3.84765625e-01,  ...,
          2.25067139e-04, -2.05039978e-04,  7.82012939e-05],
        [-9.91210938e-02,  1.70898438e-02, -2.61718750e-01,  ...,
          7.15255737e-05,  2.32696533e-04,  4.76837158e-05],
        [ 1.95312500e-01, -1.86767578e-02,  1.78710938e-01,  ...,
          4.91142273e-05,  2.78232619e-08,  2.01165676e-07],
        ...,
        [-2.81250000e-01,  3.63769531e-02, -7.18750000e-01,  ...,
          1.62124634e-04,  2.28881836e-05,  2.41994858e-05],
        [ 3.41796875e-01, -2.16064453e-02,  1.08398438e-01,  ...,
          1.16229057e-05, -4.91738319e-06, -1.13844872e-05],
        [-1.42968750e+00, -1.01318359e-02,  2.91015625e-01,  ...,
         -5.31673431e-05,  9.48905945e-05, -1.52587891e-05]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[-2.66113281e-02,  7.20214844e-03, -3.84765625e-01,  ...,
          2.25067139e-04, -2.05039978e-04,  7.82012939e-05],
        [-9.91210938e-02,  1.70898438e-02, -2.61718750e-01,  ...,
          7.15255737e-05,  2.32696533e-04,  4.76837158e-05],
        [ 1.95312500e-01, -1.86767578e-02,  1.78710938e-01,  ...,
          4.91142273e-05,  2.78232619e-08,  2.01165676e-07],
        ...,
        [-2.81250000e-01,  3.63769531e-02, -7.18750000e-01,  ...,
          1.62124634e-04,  2.28881836e-05,  2.41994858e-05],
        [ 3.41796875e-01, -2.16064453e-02,  1.08398438e-01,  ...,
          1.16229057e-05, -4.91738319e-06, -1.13844872e-05],
        [-1.42968750e+00, -1.01318359e-02,  2.91015625e-01,  ...,
         -5.31673431e-05,  9.48905945e-05, -1.52587891e-05]],
       dtype=torch.bfloat16)
================================================================================
model.layer[3].input_residual            CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[-0.01275635,  0.01428223, -0.08642578,  ...,  0.05688477,
          0.01196289, -0.03369141],
        [-0.00573730,  0.02685547, -0.05712891,  ...,  0.01385498,
         -0.01586914, -0.02697754],
        [ 0.01342773, -0.02148438,  0.01397705,  ...,  0.00753784,
         -0.00043106, -0.00063324],
        ...,
        [-0.03100586,  0.03662109, -0.02380371,  ...,  0.03039551,
         -0.00113678, -0.01116943],
        [ 0.01251221, -0.02197266,  0.01831055,  ..., -0.00111389,
         -0.00100708,  0.00463867],
        [-0.11865234, -0.01470947,  0.01867676,  ..., -0.01184082,
         -0.00759888,  0.00662231]], dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[-0.01275635,  0.01428223, -0.08642578,  ...,  0.05688477,
          0.01196289, -0.03369141],
        [-0.00573730,  0.02685547, -0.05712891,  ...,  0.01385498,
         -0.01586914, -0.02697754],
        [ 0.01342773, -0.02148438,  0.01397705,  ...,  0.00753784,
         -0.00043106, -0.00063324],
        ...,
        [-0.03100586,  0.03662109, -0.02380371,  ...,  0.03039551,
         -0.00113678, -0.01116943],
        [ 0.01251221, -0.02197266,  0.01831055,  ..., -0.00111389,
         -0.00100708,  0.00463867],
        [-0.11865234, -0.01470947,  0.01867676,  ..., -0.01184082,
         -0.00759888,  0.00662231]], dtype=torch.bfloat16)
================================================================================
model.layer[3].mlp                       CHECK_SUCCESS: False eq_num/sum: 49/106496
============================================================
tensor([[ 0.45117188, -0.09375000,  0.06005859,  ..., -0.20117188,
         -0.48828125, -0.08984375],
        [-0.21582031, -0.06738281,  0.01031494,  ..., -0.01202393,
         -0.00091553,  0.01940918],
        [-0.09521484, -0.01501465,  0.00988770,  ..., -0.00653076,
          0.00964355,  0.00817871],
        ...,
        [-0.16894531, -0.00460815,  0.05639648,  ..., -0.00329590,
          0.01177979,  0.00765991],
        [-0.14550781, -0.01458740,  0.01953125,  ...,  0.00451660,
          0.00129700, -0.00265503],
        [-0.30468750, -0.02136230, -0.06347656,  ..., -0.00497437,
         -0.00793457,  0.00205994]], dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 5.31250000e-01, -1.51367188e-01,  6.78710938e-02,  ...,
         -3.33984375e-01, -3.92578125e-01, -1.11328125e-01],
        [-5.37109375e-02, -1.66015625e-02,  2.33459473e-03,  ...,
         -3.23486328e-03,  2.49862671e-04,  5.03540039e-03],
        [-1.80664062e-02, -2.77709961e-03,  1.80053711e-03,  ...,
         -1.44958496e-03,  2.05993652e-03,  1.80816650e-03],
        ...,
        [-4.24804688e-02, -1.12915039e-03,  1.34277344e-02,  ...,
         -8.04901123e-04,  2.63977051e-03,  1.67083740e-03],
        [-2.49023438e-02, -2.45666504e-03,  3.50952148e-03,  ...,
          8.31604004e-04,  2.29835510e-04, -3.91006470e-04],
        [-4.78515625e-02, -3.23486328e-03, -9.64355469e-03,  ...,
         -7.62939453e-04, -1.29699707e-03,  2.89916992e-04]],
       dtype=torch.bfloat16)
================================================================================
model.layer[3].post_norm                 CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[ 0.00216675,  0.04028320, -0.29687500,  ...,  0.16699219,
          0.03881836, -0.06933594],
        [ 0.00418091,  0.01831055,  0.17871094,  ...,  0.04638672,
         -0.02075195, -0.05200195],
        [ 0.00454712, -0.00640869,  0.75781250,  ...,  0.06176758,
          0.01464844, -0.02441406],
        ...,
        [ 0.00463867,  0.05859375, -0.38476562,  ...,  0.11767578,
         -0.01721191, -0.04638672],
        [ 0.00521851,  0.01196289,  0.62109375,  ...,  0.01635742,
         -0.01977539, -0.01879883],
        [ 0.00601196,  0.02148438,  0.56640625,  ..., -0.02368164,
         -0.02355957,  0.00253296]], dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 0.00216675,  0.04028320, -0.29687500,  ...,  0.16699219,
          0.03881836, -0.06933594],
        [ 0.00418091,  0.01831055,  0.17871094,  ...,  0.04638672,
         -0.02075195, -0.05200195],
        [ 0.00454712, -0.00640869,  0.75781250,  ...,  0.06176758,
          0.01464844, -0.02441406],
        ...,
        [ 0.00463867,  0.05859375, -0.38476562,  ...,  0.11767578,
         -0.01721191, -0.04638672],
        [ 0.00521851,  0.01196289,  0.62109375,  ...,  0.01635742,
         -0.01977539, -0.01879883],
        [ 0.00601196,  0.02148438,  0.56640625,  ..., -0.02368164,
         -0.02355957,  0.00253296]], dtype=torch.bfloat16)
================================================================================
model.layer[3].post_norm_residual        CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[-0.37304688,  0.06591797, -0.03100586,  ...,  0.03662109,
          0.02368164, -0.02832031],
        [-0.69140625,  0.02893066,  0.01806641,  ...,  0.00982666,
         -0.01220703, -0.02050781],
        [-0.67187500, -0.00903320,  0.06835938,  ...,  0.01165771,
          0.00769043, -0.00860596],
        ...,
        [-0.63281250,  0.07617188, -0.03198242,  ...,  0.02050781,
         -0.00830078, -0.01501465],
        [-0.67187500,  0.01464844,  0.04882812,  ...,  0.00268555,
         -0.00903320, -0.00576782],
        [-0.88281250,  0.03002930,  0.05053711,  ..., -0.00442505,
         -0.01226807,  0.00088501]], dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[-0.37304688,  0.06591797, -0.03100586,  ...,  0.03662109,
          0.02368164, -0.02832031],
        [-0.69140625,  0.02893066,  0.01806641,  ...,  0.00982666,
         -0.01220703, -0.02050781],
        [-0.67187500, -0.00903320,  0.06835938,  ...,  0.01165771,
          0.00769043, -0.00860596],
        ...,
        [-0.63281250,  0.07617188, -0.03198242,  ...,  0.02050781,
         -0.00830078, -0.01501465],
        [-0.67187500,  0.01464844,  0.04882812,  ...,  0.00268555,
         -0.00903320, -0.00576782],
        [-0.88281250,  0.03002930,  0.05053711,  ..., -0.00442505,
         -0.01226807,  0.00088501]], dtype=torch.bfloat16)
================================================================================
model.layer[3].residual_norm             CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[-2.80761719e-03,  1.28784180e-02, -3.17382812e-02,  ...,
          4.58984375e-02,  1.73339844e-02, -3.83300781e-02],
        [-9.64355469e-03,  2.80761719e-02, -1.97753906e-02,  ...,
          1.33666992e-02, -1.80664062e-02, -2.14843750e-02],
        [ 1.67236328e-02, -2.70996094e-02,  1.19628906e-02,  ...,
          8.11767578e-03, -1.90734863e-06, -8.01086426e-05],
        ...,
        [-2.27050781e-02,  4.95605469e-02, -4.51660156e-02,  ...,
          2.51464844e-02, -1.47247314e-03, -9.03320312e-03],
        [ 2.51464844e-02, -2.68554688e-02,  6.22558594e-03,  ...,
          1.64794922e-03,  2.89916992e-04,  3.87573242e-03],
        [-1.20117188e-01, -1.44042969e-02,  1.90429688e-02,  ...,
         -8.60595703e-03, -6.37817383e-03,  5.95092773e-03]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[-2.80761719e-03,  1.28784180e-02, -3.17382812e-02,  ...,
          4.58984375e-02,  1.73339844e-02, -3.83300781e-02],
        [-9.64355469e-03,  2.80761719e-02, -1.97753906e-02,  ...,
          1.33666992e-02, -1.80664062e-02, -2.14843750e-02],
        [ 1.67236328e-02, -2.70996094e-02,  1.19628906e-02,  ...,
          8.11767578e-03, -1.90734863e-06, -8.01086426e-05],
        ...,
        [-2.27050781e-02,  4.95605469e-02, -4.51660156e-02,  ...,
          2.51464844e-02, -1.47247314e-03, -9.03320312e-03],
        [ 2.51464844e-02, -2.68554688e-02,  6.22558594e-03,  ...,
          1.64794922e-03,  2.89916992e-04,  3.87573242e-03],
        [-1.20117188e-01, -1.44042969e-02,  1.90429688e-02,  ...,
         -8.60595703e-03, -6.37817383e-03,  5.95092773e-03]],
       dtype=torch.bfloat16)
================================================================================
model.layer[3].self_attn                 CHECK_SUCCESS: False eq_num/sum: 19399/106496
============================================================
tensor([[-3.71093750e-01,  5.32226562e-02,  7.51495361e-04,  ...,
         -9.27734375e-03,  6.31713867e-03,  9.94873047e-03],
        [-6.83593750e-01,  8.58306885e-04,  3.78417969e-02,  ...,
         -3.52478027e-03,  5.82885742e-03,  9.15527344e-04],
        [-6.87500000e-01,  1.80664062e-02,  5.66406250e-02,  ...,
          3.54003906e-03,  7.69042969e-03, -8.54492188e-03],
        ...,
        [-6.09375000e-01,  2.67333984e-02,  1.31225586e-02,  ...,
         -4.66918945e-03, -6.83593750e-03, -5.98144531e-03],
        [-6.95312500e-01,  4.15039062e-02,  4.27246094e-02,  ...,
          1.02996826e-03, -9.33837891e-03, -9.64355469e-03],
        [-7.61718750e-01,  4.44335938e-02,  3.14941406e-02,  ...,
          4.18090820e-03, -5.88989258e-03, -5.06591797e-03]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[-3.71093750e-01,  5.41992188e-02,  5.91278076e-04,  ...,
         -9.09423828e-03,  6.22558594e-03,  1.01928711e-02],
        [-6.87500000e-01,  1.19781494e-03,  3.80859375e-02,  ...,
         -3.64685059e-03,  5.67626953e-03,  1.19781494e-03],
        [-6.87500000e-01,  1.84326172e-02,  5.68847656e-02,  ...,
          3.47900391e-03,  7.65991211e-03, -8.30078125e-03],
        ...,
        [-6.09375000e-01,  2.67333984e-02,  1.33056641e-02,  ...,
         -4.48608398e-03, -6.83593750e-03, -5.82885742e-03],
        [-6.95312500e-01,  4.17480469e-02,  4.29687500e-02,  ...,
          1.09100342e-03, -9.39941406e-03, -9.58251953e-03],
        [-7.61718750e-01,  4.44335938e-02,  3.14941406e-02,  ...,
          4.48608398e-03, -5.79833984e-03, -4.94384766e-03]],
       dtype=torch.bfloat16)
================================================================================
model.layer[3].self_attn.attn_out        CHECK_SUCCESS: False eq_num/sum: 9124/106496
============================================================
tensor([[ 0.00469971, -0.00113678, -0.00228882,  ..., -0.00126648,
         -0.00482178,  0.00476074],
        [ 0.00379944, -0.00174713, -0.00115967,  ..., -0.00081635,
         -0.00334167,  0.00183868],
        [ 0.00338745, -0.00052643, -0.00095749,  ...,  0.00086212,
         -0.00167084,  0.00204468],
        ...,
        [ 0.00154877,  0.00089264,  0.00145721,  ...,  0.00021839,
         -0.00138092,  0.00160217],
        [ 0.00139618,  0.00084686,  0.00157166,  ...,  0.00053024,
         -0.00122070,  0.00148010],
        [ 0.00110626,  0.00102234,  0.00162506,  ...,  0.00035095,
         -0.00128174,  0.00141144]], dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 0.00469971, -0.00113678, -0.00228882,  ..., -0.00126648,
         -0.00482178,  0.00476074],
        [ 0.00341797, -0.00199890, -0.00067520,  ..., -0.00097656,
         -0.00386047,  0.00286865],
        [ 0.00265503,  0.00023460, -0.00028038,  ...,  0.00087357,
         -0.00175476,  0.00233459],
        ...,
        [ 0.00159454,  0.00177002,  0.00168610,  ...,  0.00119019,
          0.00031090,  0.00133514],
        [ 0.00144196,  0.00130463,  0.00193787,  ...,  0.00139618,
          0.00064087,  0.00129700],
        [ 0.00117493,  0.00102997,  0.00201416,  ...,  0.00107574,
          0.00052261,  0.00125885]], dtype=torch.bfloat16)
================================================================================
model.layer[3].self_attn.qkv             CHECK_SUCCESS: False eq_num/sum: 50125/133120
============================================================
tensor([[-6.05468750e-01,  3.50000000e+00,  1.88281250e+00,  ...,
         -1.26647949e-03, -4.82177734e-03,  4.76074219e-03],
        [-7.50000000e-01,  3.20312500e+00,  1.84375000e+00,  ...,
          1.84059143e-04, -4.43458557e-05, -4.69970703e-03],
        [-7.26562500e-01,  2.81250000e+00,  1.71875000e+00,  ...,
          4.18090820e-03,  1.80816650e-03,  1.98364258e-03],
        ...,
        [-9.33593750e-01,  2.45312500e+00,  1.78906250e+00,  ...,
         -1.19018555e-03, -1.02539062e-02, -1.60217285e-03],
        [-7.89062500e-01,  2.62500000e+00,  1.54687500e+00,  ...,
          4.08935547e-03,  9.87052917e-05,  1.15203857e-03],
        [-8.63281250e-01,  2.70312500e+00,  1.60156250e+00,  ...,
         -4.25338745e-04,  1.74713135e-03, -3.10897827e-04]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[-6.05468750e-01,  3.50000000e+00,  1.88281250e+00,  ...,
         -1.28936768e-03, -4.97436523e-03,  5.12695312e-03],
        [-7.50000000e-01,  3.20312500e+00,  1.84375000e+00,  ...,
          3.24249268e-04, -1.30653381e-04, -4.51660156e-03],
        [-7.26562500e-01,  2.81250000e+00,  1.71093750e+00,  ...,
          4.48608398e-03,  1.92260742e-03,  2.04467773e-03],
        ...,
        [-9.33593750e-01,  2.43750000e+00,  1.78906250e+00,  ...,
         -1.05285645e-03, -1.05590820e-02, -1.61743164e-03],
        [-7.89062500e-01,  2.62500000e+00,  1.54687500e+00,  ...,
          4.48608398e-03,  1.65939331e-04,  1.15966797e-03],
        [-8.63281250e-01,  2.70312500e+00,  1.60937500e+00,  ...,
         -3.57627869e-05,  1.81579590e-03, -2.59399414e-04]],
       dtype=torch.bfloat16)
================================================================================
model.out                                CHECK_SUCCESS: True eq_num/sum: 106496/106496
============================================================
tensor([[ 1.73339844e-02, -6.40869141e-03,  6.53076172e-03,  ...,
         -4.90722656e-02, -1.33789062e-01, -3.44238281e-02],
        [-8.93750000e+00, -3.92578125e-01,  2.83203125e-01,  ...,
         -2.91748047e-02, -1.67968750e-01, -1.41601562e-02],
        [-9.18750000e+00, -2.98828125e-01,  9.49218750e-01,  ...,
          8.30078125e-02,  2.69531250e-01, -6.71386719e-03],
        ...,
        [-9.81250000e+00,  9.10156250e-01,  3.02734375e-01,  ...,
          2.85156250e-01,  5.51757812e-02, -1.17675781e-01],
        [-1.13125000e+01,  8.77380371e-04,  9.60937500e-01,  ...,
          1.34765625e-01, -1.39648438e-01, -1.52343750e-01],
        [-1.38125000e+01,  1.04003906e-01, -1.52343750e-01,  ...,
         -1.47460938e-01, -3.04687500e-01,  4.46777344e-02]],
       dtype=torch.bfloat16)
--------------------------------------------------------------------------------
tensor([[ 1.73339844e-02, -6.40869141e-03,  6.53076172e-03,  ...,
         -4.90722656e-02, -1.33789062e-01, -3.44238281e-02],
        [-8.93750000e+00, -3.92578125e-01,  2.83203125e-01,  ...,
         -2.91748047e-02, -1.67968750e-01, -1.41601562e-02],
        [-9.18750000e+00, -2.98828125e-01,  9.49218750e-01,  ...,
          8.30078125e-02,  2.69531250e-01, -6.71386719e-03],
        ...,
        [-9.81250000e+00,  9.10156250e-01,  3.02734375e-01,  ...,
          2.85156250e-01,  5.51757812e-02, -1.17675781e-01],
        [-1.13125000e+01,  8.77380371e-04,  9.60937500e-01,  ...,
          1.34765625e-01, -1.39648438e-01, -1.52343750e-01],
        [-1.38125000e+01,  1.04003906e-01, -1.52343750e-01,  ...,
         -1.47460938e-01, -3.04687500e-01,  4.46777344e-02]],
       dtype=torch.bfloat16)
================================================================================
model.token_id                           CHECK_SUCCESS: True eq_num/sum: 13/13
============================================================
tensor([100273,   2969,  93963,  93919,  16276,  93938,    851,    853,    357,
            23,  92267,  93963,  93919])
--------------------------------------------------------------------------------
tensor([100273,   2969,  93963,  93919,  16276,  93938,    851,    853,    357,
            23,  92267,  93963,  93919], dtype=torch.int32)
================================================================================
moe.gate_out                             CHECK_SUCCESS: False eq_num/sum: 81/832
============================================================
tensor([[-3.31116170e-01, -4.18516248e-01, -2.47688055e-01, -2.27028251e-01,
         -4.73752469e-01, -4.54935282e-01, -3.42577010e-01, -2.10358754e-01,
         -5.24582267e-01, -2.00420827e-01, -2.54924923e-01, -6.32237971e-01,
         -5.68692923e-01, -5.75386643e-01, -3.40261668e-01,  5.71447127e-02,
         -1.56031013e-01, -2.55992085e-01, -4.28503782e-01, -5.49766243e-01,
         -1.77429482e-01, -1.79667935e-01, -5.56164563e-01,  1.31039536e+00,
         -2.55557716e-01, -6.91116691e-01, -7.61348009e-01, -9.68236327e-02,
          6.03174067e+00, -3.47742081e-01,  9.83472466e-01, -5.14740348e-01,
         -2.11712137e-01, -1.90406770e-01, -2.56011367e-01,  1.73805170e-02,
         -4.20874566e-01,  3.56217295e-01, -1.86620176e-01, -3.25278282e-01,
         -2.91701376e-01, -2.28303775e-01, -1.42905250e-01, -6.76241219e-01,
         -2.56495088e-01, -3.62078458e-01, -3.77525657e-01, -4.97015625e-01,
         -6.70217931e-01, -4.66535926e-01, -4.11814123e-01, -5.97215116e-01,
         -1.98342726e-01, -8.51261258e-01, -4.21582252e-01, -4.84417081e-01,
         -7.88489282e-01, -3.22963238e-01, -4.55078095e-01, -1.32534727e-01,
         -4.56932813e-01, -4.89606917e-01, -1.28575027e-01, -5.00908315e-01],
        [ 2.24648178e-01, -1.25773773e-02,  3.95037919e-01,  1.69335961e-01,
          3.56839210e-01,  1.33020682e-02,  9.29031745e-02,  1.02634147e-01,
          3.32111232e-02,  3.26764852e-01,  1.29555956e-01,  5.87385118e-01,
         -1.39453351e-01,  1.55493245e-01,  3.21965426e-01,  7.50708878e-01,
          1.25354946e+00,  7.99810469e-01,  3.30886811e-01, -1.65246546e-01,
          3.46512973e-01,  1.93164304e-01,  3.53529245e-01,  7.76003599e-01,
          6.40623510e-01,  3.67625803e-03, -2.91398317e-01,  2.90947616e-01,
         -6.64935589e+00,  3.49754900e-01,  1.50242901e+00,  2.54758239e-01,
          6.42811239e-01,  1.90586925e-01, -1.66346774e-01,  3.19084436e-01,
          6.09330118e-01,  5.87370813e-01,  4.60010171e-01,  7.81852826e-02,
          3.43667328e-01,  2.11126849e-01,  7.32832670e-01,  7.27159344e-03,
          3.35546315e-01,  5.35966396e-01,  7.56338298e-01, -8.09375644e-02,
          1.17319889e-01,  1.82478383e-01, -7.68713877e-02,  3.32429677e-01,
          5.09798050e-01,  1.48856544e+00, -3.61091524e-01,  2.70897835e-01,
          7.61829987e-02, -6.08987175e-02, -2.98382696e-02,  8.99958462e-02,
          1.86924502e-01,  6.53706193e-01,  2.42109284e-01, -3.82511497e-01],
        [ 3.77747923e-01,  2.08580941e-01,  5.08757114e-01,  7.31644750e-01,
          5.57417810e-01,  4.06554967e-01, -8.86119232e-02,  3.79246384e-01,
          8.14431667e-01,  5.99907756e-01,  1.00317204e+00,  5.26350379e-01,
          3.82417947e-01,  4.44741428e-01,  6.78029776e-01,  4.72743094e-01,
         -1.21799149e-01,  3.23898256e-01,  5.58097124e-01,  2.26846680e-01,
          7.24864364e-01,  4.18417066e-01,  1.40131131e-01,  9.67328727e-01,
          3.04881871e-01,  6.59971297e-01,  6.33023977e-01,  5.32576501e-01,
         -7.64077377e+00,  1.24315821e-01,  1.22142673e+00,  3.90389293e-01,
          5.24007857e-01,  5.17937601e-01,  8.68575871e-01,  5.04238784e-01,
         -3.39510702e-02,  5.86249053e-01,  4.44228590e-01,  7.18667805e-01,
          4.41703767e-01,  4.75035608e-01,  6.81616068e-01,  2.63950616e-01,
          4.38909918e-01,  1.07596003e-01,  6.92034662e-01,  7.66556144e-01,
          3.93169940e-01,  3.12642246e-01,  6.16054058e-01,  9.24666151e-02,
         -3.11275154e-01, -1.95890769e-01,  6.08164012e-01,  4.95786726e-01,
          6.27680346e-02,  2.34558761e-01,  6.53231919e-01,  4.21568483e-01,
          1.77398816e-01,  2.53232926e-01,  8.89425039e-01, -8.78841802e-02],
        [ 3.99001747e-01,  2.22721055e-01,  3.86112392e-01,  5.78548372e-01,
          3.98218125e-01,  2.74467558e-01,  2.86533803e-01,  3.58316422e-01,
          3.33974242e-01,  4.79444921e-01,  6.37531042e-01,  5.98536134e-01,
          1.65354565e-01,  4.39273059e-01,  6.23889625e-01,  6.39539957e-01,
          3.91814262e-01,  4.47276533e-01,  5.64798355e-01, -5.82557395e-02,
          3.43038201e-01,  5.51981807e-01,  4.93589997e-01,  7.05546796e-01,
          4.45903212e-01,  4.04817432e-01,  5.35431862e-01,  5.76245248e-01,
         -6.12835407e+00,  4.44469243e-01,  1.11027086e+00,  2.01255262e-01,
          4.38948363e-01,  7.85175622e-01,  7.25157678e-01,  3.80636752e-01,
          2.87531406e-01,  5.51081121e-01,  2.93736875e-01,  3.70355725e-01,
          5.70800126e-01,  6.72247648e-01,  6.06783032e-01,  4.09707665e-01,
          5.80624819e-01,  5.58854997e-01,  4.84733015e-01,  8.01691055e-01,
          7.37801641e-02,  4.74448204e-01,  4.02661353e-01,  5.49462065e-03,
          2.07907632e-01,  4.71488357e-01,  5.24930656e-01,  5.27927637e-01,
         -9.05151758e-03,  3.43621075e-01,  5.26086152e-01,  3.85081291e-01,
          5.07007420e-01,  5.11751831e-01,  7.17584133e-01,  6.53106034e-01],
        [-7.17074633e-01, -5.16828895e-02, -7.43013769e-02, -4.31308568e-01,
         -1.57267526e-01,  2.04161763e-01,  5.79039037e-01,  3.24692905e-01,
         -4.55807596e-02, -8.29409063e-02,  2.18858525e-01,  6.95933178e-02,
         -1.63862959e-01, -5.51381670e-02,  2.20361069e-01,  6.05167985e-01,
          4.15488273e-01,  5.59508026e-01, -2.30062738e-01, -4.41009812e-02,
          1.08969007e-02,  1.64128944e-01,  2.74246901e-01,  1.06392927e-01,
          9.30749059e-01, -1.36300012e-01,  1.29406944e-01,  2.54539728e-01,
         -4.76181364e+00,  2.71250367e-01,  4.81017441e-01,  7.18569160e-02,
          1.02373981e+00,  6.93722889e-02, -2.24364966e-01,  3.49831462e-01,
         -3.85385036e-01,  4.38027471e-01, -1.50466710e-01,  2.89590716e-01,
          3.17905575e-01,  3.42029631e-01,  2.80052543e-01,  1.40545860e-01,
          2.05336720e-01,  6.17231131e-01, -8.97891372e-02, -5.40210903e-01,
         -3.48433495e-01,  2.27648109e-01,  5.69314137e-02, -2.71060705e-01,
          8.76025915e-01,  5.36591411e-01, -5.66614807e-01,  9.92467031e-02,
         -4.73703504e-01,  5.05800784e-01, -2.95549452e-01,  2.63527215e-01,
          3.44917238e-01,  9.94354963e-01, -2.71168537e-02,  3.07318747e-01],
        [ 4.71021026e-01,  4.52521116e-01,  2.18839049e-01,  9.19720352e-01,
          3.68510962e-01,  2.01232165e-01, -2.20278576e-01,  4.12884414e-01,
          2.26376995e-01,  6.48624957e-01,  6.00076795e-01,  8.74989033e-01,
          4.71293539e-01,  8.66570115e-01,  2.43859768e-01,  2.37777531e-01,
          4.92639124e-01,  1.03723049e-01,  3.98322612e-01,  3.54338735e-01,
          4.89295065e-01,  2.46366799e-01, -4.32953350e-02,  5.60283422e-01,
          1.35741651e-01,  4.53177273e-01,  1.90514237e-01,  2.64015526e-01,
         -3.86168075e+00,  5.13215438e-02,  6.85039461e-01,  1.91023156e-01,
          5.87682307e-01,  4.52156454e-01,  3.86722028e-01,  4.36467022e-01,
          3.80091846e-01,  3.13090026e-01,  7.39587903e-01,  7.31566548e-01,
          6.19411111e-01, -3.59023243e-01,  5.88786900e-01, -2.90070385e-01,
          3.09748918e-01, -3.24232161e-01,  8.35575938e-01,  8.90593767e-01,
          3.62533063e-01,  3.68430048e-01,  2.98518419e-01, -3.89300972e-01,
         -4.59371984e-01,  3.61984521e-02,  5.82695544e-01,  5.96458197e-01,
          7.67913535e-02, -5.29460423e-02,  7.01975703e-01,  2.86421180e-01,
         -2.47142296e-02,  1.44124597e-01,  8.06299090e-01,  3.61220032e-01],
        [-1.32164702e-01,  1.22897997e-01,  2.33157072e-03, -1.88826889e-01,
          9.95808169e-02, -2.34460697e-01,  6.75244808e-01,  2.42176771e-01,
          1.85019881e-01,  1.87829256e-01,  3.50429326e-01,  7.24075913e-01,
          3.26874517e-02, -1.26738735e-02,  7.50393331e-01,  1.98913008e-01,
          4.07246023e-01,  4.62414294e-01,  3.60029131e-01, -4.03647900e-01,
         -3.24660420e-01,  1.61658794e-01,  1.77107170e-01,  1.00995168e-01,
          1.43845499e-01,  6.71060896e-03,  1.64817899e-01,  1.68230310e-01,
         -3.67432189e+00,  1.33435115e-01,  3.72165084e-01,  1.56146884e-01,
          3.09920371e-01,  2.62527913e-01,  1.45946145e-01, -1.78099483e-01,
         -1.64432451e-01,  3.96663040e-01, -3.08849335e-01,  7.54071772e-02,
          5.66065848e-01, -1.01718098e-01,  4.11821634e-01,  6.69938624e-01,
          3.16321939e-01,  4.07577962e-01,  1.98056847e-01,  2.07703561e-01,
         -1.64895058e-01,  4.69275981e-01,  2.49661267e-01, -1.32493824e-01,
          4.64437872e-01,  5.37734687e-01,  7.05860913e-01,  4.01298553e-01,
         -3.10499787e-01,  3.17160308e-01, -2.31528971e-02,  3.33005935e-01,
          3.45492214e-01,  2.10854307e-01,  4.14278865e-01,  4.07439679e-01],
        [-2.14673832e-01,  2.29186848e-01, -8.68042186e-02, -2.40642950e-01,
          1.71152160e-01,  7.15478957e-02,  1.96234524e-01, -5.42177558e-01,
          7.10137188e-02,  7.68982232e-01,  2.85231501e-01,  4.55277741e-01,
         -6.83717132e-01,  1.03188530e-01, -7.49919564e-05,  4.01161939e-01,
          7.03293234e-02,  1.78907692e-01,  1.94617182e-01,  1.61007792e-02,
          3.80388439e-01,  1.55665889e-01,  1.01177275e-01,  1.25869602e-01,
          3.85864794e-01, -1.40593708e-01,  2.18781263e-01,  1.01691797e-01,
         -3.55491734e+00,  6.90820456e-01,  2.92863965e-01,  1.57791406e-01,
          1.67797431e-01,  1.81057557e-01, -7.01737925e-02,  3.02132964e-01,
          1.30194739e-01,  1.64797142e-01,  3.57064568e-02, -5.14718704e-02,
          4.13681090e-01,  4.10763532e-01,  9.88583803e-01, -1.68905735e-01,
          1.90409824e-01,  8.30448642e-02,  2.74887830e-01, -6.55154660e-02,
          6.77176833e-01,  1.98182657e-01,  2.42158920e-01, -1.54674038e-01,
         -1.85656592e-01,  2.27722690e-01,  5.92523456e-01, -1.98672134e-02,
         -2.74139494e-01, -2.35251382e-01, -4.94235978e-02,  2.60967482e-02,
         -4.55934815e-02,  4.78923291e-01,  1.16113871e-01,  1.36252880e-01],
        [ 3.30957770e-01,  4.87857729e-01,  5.57420909e-01,  1.93175953e-02,
          3.71879727e-01,  1.85983226e-01,  1.77101806e-01,  5.69035888e-01,
          6.66727662e-01,  6.74373627e-01,  2.63677835e-01,  3.64639372e-01,
          5.57499468e-01,  3.42499852e-01,  2.35318020e-01,  1.03134051e-01,
          2.23533306e-02,  1.03666067e-01,  1.05666971e+00,  4.29997474e-01,
          5.13681114e-01,  2.34959722e-01, -1.66535079e-02,  1.91035867e-01,
          3.19881923e-02,  4.70418930e-01,  3.58050168e-01,  1.02471687e-01,
         -4.03167343e+00, -3.36136132e-01,  4.38663542e-01,  3.83749008e-01,
          3.08071166e-01,  3.23709130e-01,  4.21706110e-01,  2.74992853e-01,
          1.37321547e-01,  3.47097337e-01,  1.69654578e-01,  3.03862810e-01,
          5.27655661e-01, -3.30532730e-01,  1.30054519e-01, -4.76268470e-01,
          2.43192434e-01, -2.07826104e-02,  5.44105291e-01,  4.93551463e-01,
         -5.30708283e-02,  3.06833267e-01,  6.04654849e-01, -7.72038817e-01,
          8.20338205e-02,  1.54514596e-01,  7.20628917e-01,  4.10088688e-01,
         -5.94631955e-03, -1.33234844e-01,  3.81676108e-01,  4.30561930e-01,
         -2.15670884e-01,  1.45982668e-01,  8.10568094e-01,  1.32533967e-01],
        [ 4.64176178e-01,  5.04491150e-01,  3.83324951e-01,  3.67045552e-01,
          5.51271915e-01,  3.78663570e-01, -1.90608278e-01,  2.05090955e-01,
          5.42928457e-01,  3.86245847e-01,  3.79198164e-01,  1.08225532e-01,
          1.56118333e-01,  3.72719824e-01,  2.04176456e-03,  2.71985680e-01,
          1.65228639e-02, -1.20034285e-01,  3.34697932e-01,  5.34476936e-01,
          4.22068268e-01,  2.65262157e-01,  2.55918235e-01,  3.92180830e-01,
         -1.18575580e-02,  6.11985028e-01,  2.39898860e-01,  3.10126901e-01,
         -1.98609936e+00, -8.13991502e-02,  5.17089188e-01,  4.32735801e-01,
          3.33067000e-01,  4.28862333e-01,  3.44920814e-01,  4.04316247e-01,
          2.94493735e-01,  5.92897892e-01,  2.00739041e-01,  3.24670017e-01,
          4.13053721e-01,  2.39046752e-01,  3.10702384e-01, -3.63594532e-01,
          3.53845745e-01, -5.57498276e-01,  2.72418946e-01,  8.85126412e-01,
          4.50057924e-01, -9.04601663e-02,  5.25855482e-01,  3.66920650e-01,
         -1.48102701e-01, -1.60491541e-01,  9.26530957e-02,  3.51758838e-01,
          8.00553203e-01, -3.47269416e-01,  9.71200347e-01,  2.19737545e-01,
          3.15856904e-01, -1.27139181e-01,  5.24563313e-01,  2.40770236e-01],
        [-2.40892336e-01, -9.85157862e-02, -2.23578420e-02, -2.23295704e-01,
         -1.25614524e-01, -5.98082840e-02,  4.92994517e-01, -4.44729745e-01,
          5.33858165e-02, -1.81538254e-01,  1.60000727e-01, -3.83997202e-01,
         -4.57157314e-01, -1.61891267e-01, -2.51364522e-02,  1.00528157e+00,
          3.75859231e-01,  8.51481259e-01, -1.42668977e-01, -4.18564677e-02,
          6.08797334e-02,  1.62551731e-01,  2.23527923e-01, -1.78828137e-03,
          4.50995684e-01, -2.37530485e-01, -2.69343793e-01,  2.61102110e-01,
         -2.57360888e+00,  3.02977353e-01,  3.86745960e-01,  2.72833973e-01,
          3.21006715e-01,  6.48979619e-02, -3.15890551e-01, -1.45636499e-01,
         -2.64472216e-01,  1.19071889e+00,  7.90163353e-02, -2.76822373e-02,
          1.14128269e-01, -7.40212738e-04,  4.35432613e-01, -3.10342908e-02,
          2.17780173e-01,  7.02084482e-01,  2.98920125e-02, -4.66818064e-01,
         -1.28633589e-01,  2.89398462e-01, -1.15014754e-01,  3.07614684e-01,
          4.92658913e-01,  3.04484904e-01, -8.00470114e-01,  1.34866804e-01,
         -5.82501173e-01,  8.34716499e-01, -3.21505666e-01,  1.92138195e-01,
         -7.66735896e-02,  8.88491273e-01, -1.86380088e-01,  4.00690556e-01],
        [ 4.88947093e-01,  2.60339379e-01,  7.24073648e-02,  2.00816423e-01,
          2.71944731e-01, -1.51762396e-01, -1.79436505e-01,  4.47633713e-01,
          2.48434231e-01,  2.54889756e-01,  3.54483634e-01,  5.18203855e-01,
          6.77662671e-01,  3.68306160e-01,  5.47302067e-01,  1.46432698e-01,
          2.50548899e-01,  1.29683524e-01,  2.16628954e-01,  1.06934592e-01,
          1.73040166e-01,  1.96693227e-01,  1.87752470e-01,  8.06029499e-01,
          3.40997688e-02,  5.29780686e-01,  9.89805833e-02,  2.75516063e-01,
         -2.23717999e+00, -2.36318149e-02,  5.26788354e-01,  3.56938988e-01,
          3.80675584e-01,  2.62154341e-01,  3.59499931e-01, -9.40147117e-02,
          1.61807269e-01,  1.93353772e-01,  1.46806076e-01,  3.28952223e-01,
          4.69561130e-01, -1.94296852e-01,  4.37392592e-01,  2.21740961e-01,
          2.76418388e-01, -1.51914433e-01,  2.98237145e-01,  4.37440425e-01,
          2.10303485e-01,  3.31998050e-01,  5.60386121e-01,  4.50065434e-01,
         -2.26157829e-01, -1.64372772e-01,  3.33993793e-01,  3.82742763e-01,
          9.42961574e-02,  1.18957110e-01,  4.12094116e-01,  4.45325226e-01,
          2.72894323e-01, -4.74880710e-02,  6.33072197e-01, -6.01167046e-03],
        [ 3.15092444e-01,  2.45625421e-01,  1.25141323e-01,  3.20375264e-01,
          2.13272899e-01,  1.78446062e-02,  3.12721670e-01,  1.80294663e-01,
          7.96114206e-02,  1.20749146e-01,  2.96798944e-01,  3.44896227e-01,
          9.52603146e-02,  3.06152493e-01,  5.18863738e-01,  4.83877212e-01,
          3.33137721e-01,  2.98338562e-01,  3.43336910e-01, -9.20509249e-02,
          1.60935298e-01,  3.55694801e-01,  3.67381543e-01,  4.98973340e-01,
          2.85067409e-01,  3.04178506e-01,  2.97820598e-01,  3.78827035e-01,
         -2.04565883e+00,  3.39942157e-01,  5.61451077e-01,  1.82167456e-01,
          2.84137726e-01,  6.54615641e-01,  4.29946303e-01,  4.63775508e-02,
          1.60107717e-01,  3.32432181e-01,  7.37644434e-02,  1.78658962e-01,
          4.20172900e-01,  3.78236383e-01,  3.88496101e-01,  3.23066086e-01,
          4.57601756e-01,  4.01433766e-01,  2.11384967e-01,  3.89359534e-01,
          1.01739451e-01,  4.14737880e-01,  3.06361496e-01,  1.20544598e-01,
          1.61366701e-01,  4.34631377e-01,  2.99117476e-01,  2.72031248e-01,
          5.89464046e-02,  2.03927368e-01,  3.17846477e-01,  2.62769729e-01,
          4.76920396e-01,  3.02744210e-01,  4.93431062e-01,  5.05203664e-01]])
--------------------------------------------------------------------------------
tensor([[-3.31116080e-01, -4.18516129e-01, -2.47687936e-01, -2.27028102e-01,
         -4.73752469e-01, -4.54935104e-01, -3.42577219e-01, -2.10358739e-01,
         -5.24582207e-01, -2.00420663e-01, -2.54924953e-01, -6.32238150e-01,
         -5.68692744e-01, -5.75386465e-01, -3.40261638e-01,  5.71446344e-02,
         -1.56031057e-01, -2.55991966e-01, -4.28503692e-01, -5.49766004e-01,
         -1.77429259e-01, -1.79667890e-01, -5.56164503e-01,  1.31039500e+00,
         -2.55557686e-01, -6.91116512e-01, -7.61348069e-01, -9.68235582e-02,
          6.03173971e+00, -3.47742051e-01,  9.83472526e-01, -5.14739990e-01,
         -2.11712122e-01, -1.90406710e-01, -2.56011307e-01,  1.73805244e-02,
         -4.20874625e-01,  3.56217146e-01, -1.86620086e-01, -3.25278103e-01,
         -2.91701287e-01, -2.28304014e-01, -1.42905295e-01, -6.76241040e-01,
         -2.56495118e-01, -3.62078428e-01, -3.77525568e-01, -4.97015446e-01,
         -6.70217633e-01, -4.66535985e-01, -4.11814094e-01, -5.97214818e-01,
         -1.98342711e-01, -8.51261258e-01, -4.21582133e-01, -4.84417021e-01,
         -7.88488984e-01, -3.22963268e-01, -4.55077857e-01, -1.32534951e-01,
         -4.56932694e-01, -4.89606857e-01, -1.28574908e-01, -5.00908494e-01],
        [ 2.24648133e-01, -1.25772031e-02,  3.95037889e-01,  1.69336110e-01,
          3.56839210e-01,  1.33020692e-02,  9.29030553e-02,  1.02634117e-01,
          3.32111567e-02,  3.26764792e-01,  1.29556000e-01,  5.87384701e-01,
         -1.39453366e-01,  1.55493364e-01,  3.21965396e-01,  7.50709057e-01,
          1.25354970e+00,  7.99810231e-01,  3.30886781e-01, -1.65246472e-01,
          3.46512914e-01,  1.93164378e-01,  3.53529423e-01,  7.76003599e-01,
          6.40623510e-01,  3.67642753e-03, -2.91398227e-01,  2.90947527e-01,
         -6.64935446e+00,  3.49754840e-01,  1.50242877e+00,  2.54758388e-01,
          6.42811179e-01,  1.90586895e-01, -1.66346803e-01,  3.19084734e-01,
          6.09330177e-01,  5.87370753e-01,  4.60010171e-01,  7.81853050e-02,
          3.43667299e-01,  2.11126819e-01,  7.32832611e-01,  7.27168238e-03,
          3.35546345e-01,  5.35966277e-01,  7.56338418e-01, -8.09374973e-02,
          1.17319904e-01,  1.82478428e-01, -7.68713132e-02,  3.32429439e-01,
          5.09797990e-01,  1.48856497e+00, -3.61091524e-01,  2.70897985e-01,
          7.61830062e-02, -6.08987845e-02, -2.98382789e-02,  8.99956971e-02,
          1.86924323e-01,  6.53705895e-01,  2.42109165e-01, -3.82511497e-01],
        [ 3.77747804e-01,  2.08580762e-01,  5.08757055e-01,  7.31645048e-01,
          5.57417929e-01,  4.06554937e-01, -8.86119604e-02,  3.79246324e-01,
          8.14431548e-01,  5.99907696e-01,  1.00317216e+00,  5.26350319e-01,
          3.82417917e-01,  4.44741547e-01,  6.78029656e-01,  4.72742975e-01,
         -1.21799245e-01,  3.23898345e-01,  5.58097005e-01,  2.26846755e-01,
          7.24864364e-01,  4.18417096e-01,  1.40131101e-01,  9.67328608e-01,
          3.04881930e-01,  6.59971178e-01,  6.33023858e-01,  5.32576740e-01,
         -7.64077330e+00,  1.24315925e-01,  1.22142649e+00,  3.90389264e-01,
          5.24007738e-01,  5.17937601e-01,  8.68575871e-01,  5.04238844e-01,
         -3.39510813e-02,  5.86249232e-01,  4.44228560e-01,  7.18667924e-01,
          4.41703677e-01,  4.75035489e-01,  6.81616008e-01,  2.63950497e-01,
          4.38909799e-01,  1.07596003e-01,  6.92034423e-01,  7.66556025e-01,
          3.93169910e-01,  3.12642276e-01,  6.16053939e-01,  9.24666077e-02,
         -3.11275154e-01, -1.95890844e-01,  6.08163953e-01,  4.95786607e-01,
          6.27681166e-02,  2.34558702e-01,  6.53231859e-01,  4.21568453e-01,
          1.77398801e-01,  2.53233045e-01,  8.89425337e-01, -8.78841132e-02],
        [ 3.99001688e-01,  2.22720802e-01,  3.86112183e-01,  5.78548253e-01,
          3.98218125e-01,  2.74467498e-01,  2.86533713e-01,  3.58316511e-01,
          3.33974093e-01,  4.79445130e-01,  6.37531042e-01,  5.98536015e-01,
          1.65354580e-01,  4.39272791e-01,  6.23889625e-01,  6.39540136e-01,
          3.91814202e-01,  4.47276503e-01,  5.64798653e-01, -5.82557805e-02,
          3.43038410e-01,  5.51981568e-01,  4.93589997e-01,  7.05546618e-01,
          4.45903420e-01,  4.04817343e-01,  5.35431862e-01,  5.76245189e-01,
         -6.12835646e+00,  4.44469213e-01,  1.11027086e+00,  2.01255172e-01,
          4.38948303e-01,  7.85175622e-01,  7.25157857e-01,  3.80636692e-01,
          2.87531346e-01,  5.51081181e-01,  2.93736815e-01,  3.70355785e-01,
          5.70800304e-01,  6.72247708e-01,  6.06783032e-01,  4.09707516e-01,
          5.80624700e-01,  5.58854997e-01,  4.84732956e-01,  8.01690817e-01,
          7.37802759e-02,  4.74448115e-01,  4.02661294e-01,  5.49462019e-03,
          2.07907692e-01,  4.71488297e-01,  5.24930656e-01,  5.27927637e-01,
         -9.05149058e-03,  3.43621045e-01,  5.26086211e-01,  3.85081202e-01,
          5.07007480e-01,  5.11751831e-01,  7.17584074e-01,  6.53105915e-01],
        [-7.17074454e-01, -5.16828634e-02, -7.43012875e-02, -4.31308419e-01,
         -1.57267466e-01,  2.04161778e-01,  5.79038978e-01,  3.24692875e-01,
         -4.55808118e-02, -8.29408616e-02,  2.18858480e-01,  6.95932880e-02,
         -1.63862899e-01, -5.51381558e-02,  2.20361024e-01,  6.05168104e-01,
          4.15488362e-01,  5.59508026e-01, -2.30062708e-01, -4.41009365e-02,
          1.08968802e-02,  1.64128765e-01,  2.74246633e-01,  1.06392905e-01,
          9.30749059e-01, -1.36299923e-01,  1.29406929e-01,  2.54539520e-01,
         -4.76181459e+00,  2.71250367e-01,  4.81017560e-01,  7.18570277e-02,
          1.02373970e+00,  6.93723410e-02, -2.24364921e-01,  3.49831492e-01,
         -3.85385007e-01,  4.38027442e-01, -1.50466591e-01,  2.89590746e-01,
          3.17905575e-01,  3.42029512e-01,  2.80052572e-01,  1.40545860e-01,
          2.05336645e-01,  6.17230892e-01, -8.97890627e-02, -5.40210724e-01,
         -3.48433316e-01,  2.27647960e-01,  5.69313541e-02, -2.71060854e-01,
          8.76025856e-01,  5.36591351e-01, -5.66614807e-01,  9.92467180e-02,
         -4.73703384e-01,  5.05800903e-01, -2.95549363e-01,  2.63527215e-01,
          3.44917089e-01,  9.94354844e-01, -2.71168314e-02,  3.07318658e-01],
        [ 4.71021056e-01,  4.52521056e-01,  2.18839139e-01,  9.19719994e-01,
          3.68510932e-01,  2.01232061e-01, -2.20278621e-01,  4.12884414e-01,
          2.26377025e-01,  6.48625195e-01,  6.00076795e-01,  8.74988914e-01,
          4.71293598e-01,  8.66569936e-01,  2.43859783e-01,  2.37777472e-01,
          4.92639095e-01,  1.03723027e-01,  3.98322642e-01,  3.54338855e-01,
          4.89295095e-01,  2.46366918e-01, -4.32953537e-02,  5.60283303e-01,
          1.35741651e-01,  4.53177154e-01,  1.90514266e-01,  2.64015615e-01,
         -3.86168003e+00,  5.13215177e-02,  6.85039222e-01,  1.91023201e-01,
          5.87682068e-01,  4.52156305e-01,  3.86721849e-01,  4.36467201e-01,
          3.80091757e-01,  3.13089997e-01,  7.39587963e-01,  7.31566668e-01,
          6.19411290e-01, -3.59023154e-01,  5.88786900e-01, -2.90070355e-01,
          3.09749037e-01, -3.24232101e-01,  8.35575938e-01,  8.90594006e-01,
          3.62533092e-01,  3.68430048e-01,  2.98518330e-01, -3.89300764e-01,
         -4.59371984e-01,  3.61984596e-02,  5.82695603e-01,  5.96458256e-01,
          7.67914578e-02, -5.29459976e-02,  7.01975703e-01,  2.86421269e-01,
         -2.47142632e-02,  1.44124687e-01,  8.06298971e-01,  3.61220062e-01],
        [-1.32164568e-01,  1.22898042e-01,  2.33174581e-03, -1.88826814e-01,
          9.95808616e-02, -2.34460562e-01,  6.75244510e-01,  2.42176667e-01,
          1.85019985e-01,  1.87829226e-01,  3.50429267e-01,  7.24076033e-01,
          3.26875634e-02, -1.26738660e-02,  7.50393510e-01,  1.98913023e-01,
          4.07246023e-01,  4.62414116e-01,  3.60029101e-01, -4.03647810e-01,
         -3.24660391e-01,  1.61658749e-01,  1.77107230e-01,  1.00995228e-01,
          1.43845439e-01,  6.71072025e-03,  1.64817944e-01,  1.68230236e-01,
         -3.67432141e+00,  1.33435056e-01,  3.72165233e-01,  1.56146854e-01,
          3.09920371e-01,  2.62527943e-01,  1.45946115e-01, -1.78099439e-01,
         -1.64432392e-01,  3.96662951e-01, -3.08849245e-01,  7.54072294e-02,
          5.66065907e-01, -1.01718172e-01,  4.11821663e-01,  6.69938684e-01,
          3.16321909e-01,  4.07577902e-01,  1.98056892e-01,  2.07703665e-01,
         -1.64894968e-01,  4.69275802e-01,  2.49661297e-01, -1.32493764e-01,
          4.64437693e-01,  5.37734628e-01,  7.05860794e-01,  4.01298583e-01,
         -3.10499549e-01,  3.17160130e-01, -2.31529474e-02,  3.33005995e-01,
          3.45492363e-01,  2.10854337e-01,  4.14278954e-01,  4.07439470e-01],
        [-2.14673787e-01,  2.29186863e-01, -8.68041813e-02, -2.40642950e-01,
          1.71152189e-01,  7.15479627e-02,  1.96234480e-01, -5.42177558e-01,
          7.10137710e-02,  7.68982112e-01,  2.85231441e-01,  4.55277830e-01,
         -6.83717072e-01,  1.03188649e-01, -7.49751925e-05,  4.01161999e-01,
          7.03293309e-02,  1.78907797e-01,  1.94617257e-01,  1.61008015e-02,
          3.80388379e-01,  1.55665994e-01,  1.01177245e-01,  1.25869557e-01,
          3.85864913e-01, -1.40593678e-01,  2.18781322e-01,  1.01691857e-01,
         -3.55491686e+00,  6.90820336e-01,  2.92864054e-01,  1.57791391e-01,
          1.67797491e-01,  1.81057483e-01, -7.01738149e-02,  3.02132994e-01,
          1.30194873e-01,  1.64797157e-01,  3.57064307e-02, -5.14719486e-02,
          4.13681209e-01,  4.10763592e-01,  9.88583744e-01, -1.68905675e-01,
          1.90409854e-01,  8.30448493e-02,  2.74887800e-01, -6.55153990e-02,
          6.77176654e-01,  1.98182717e-01,  2.42158964e-01, -1.54673994e-01,
         -1.85656577e-01,  2.27722734e-01,  5.92523456e-01, -1.98672451e-02,
         -2.74139345e-01, -2.35251367e-01, -4.94235046e-02,  2.60966588e-02,
         -4.55934890e-02,  4.78923321e-01,  1.16113894e-01,  1.36252910e-01],
        [ 3.30957770e-01,  4.87857610e-01,  5.57420731e-01,  1.93176810e-02,
          3.71879667e-01,  1.85983300e-01,  1.77101806e-01,  5.69035947e-01,
          6.66727841e-01,  6.74373388e-01,  2.63677776e-01,  3.64639252e-01,
          5.57499349e-01,  3.42499852e-01,  2.35317945e-01,  1.03134170e-01,
          2.23533884e-02,  1.03666112e-01,  1.05666959e+00,  4.29997236e-01,
          5.13680935e-01,  2.34959766e-01, -1.66535359e-02,  1.91035867e-01,
          3.19881886e-02,  4.70418811e-01,  3.58050078e-01,  1.02471657e-01,
         -4.03167439e+00, -3.36136073e-01,  4.38663512e-01,  3.83749008e-01,
          3.08071196e-01,  3.23709011e-01,  4.21706051e-01,  2.74992943e-01,
          1.37321576e-01,  3.47097337e-01,  1.69654503e-01,  3.03862780e-01,
          5.27655602e-01, -3.30532610e-01,  1.30054459e-01, -4.76268530e-01,
          2.43192375e-01, -2.07825601e-02,  5.44105232e-01,  4.93551522e-01,
         -5.30708544e-02,  3.06833208e-01,  6.04654789e-01, -7.72038698e-01,
          8.20338428e-02,  1.54514655e-01,  7.20629096e-01,  4.10088599e-01,
         -5.94636705e-03, -1.33234769e-01,  3.81676048e-01,  4.30561781e-01,
         -2.15670943e-01,  1.45982847e-01,  8.10568154e-01,  1.32534087e-01],
        [ 4.64176208e-01,  5.04491210e-01,  3.83324921e-01,  3.67045462e-01,
          5.51271737e-01,  3.78663599e-01, -1.90608218e-01,  2.05090985e-01,
          5.42928457e-01,  3.86245877e-01,  3.79198164e-01,  1.08225487e-01,
          1.56118274e-01,  3.72719914e-01,  2.04172498e-03,  2.71985680e-01,
          1.65228955e-02, -1.20034203e-01,  3.34697783e-01,  5.34476876e-01,
          4.22068238e-01,  2.65262216e-01,  2.55918235e-01,  3.92180830e-01,
         -1.18575059e-02,  6.11984849e-01,  2.39898756e-01,  3.10126960e-01,
         -1.98609972e+00, -8.13991129e-02,  5.17089248e-01,  4.32735652e-01,
          3.33067000e-01,  4.28862333e-01,  3.44920754e-01,  4.04316306e-01,
          2.94493705e-01,  5.92897832e-01,  2.00738966e-01,  3.24669898e-01,
          4.13053840e-01,  2.39046812e-01,  3.10702294e-01, -3.63594472e-01,
          3.53845775e-01, -5.57498157e-01,  2.72418857e-01,  8.85126352e-01,
          4.50057894e-01, -9.04600918e-02,  5.25855362e-01,  3.66920561e-01,
         -1.48102656e-01, -1.60491496e-01,  9.26530585e-02,  3.51758838e-01,
          8.00552726e-01, -3.47269297e-01,  9.71200109e-01,  2.19737530e-01,
          3.15856785e-01, -1.27139032e-01,  5.24563432e-01,  2.40770221e-01],
        [-2.40892231e-01, -9.85157639e-02, -2.23578624e-02, -2.23295704e-01,
         -1.25614509e-01, -5.98082729e-02,  4.92994487e-01, -4.44729626e-01,
          5.33858277e-02, -1.81538150e-01,  1.60000578e-01, -3.83997083e-01,
         -4.57157254e-01, -1.61891267e-01, -2.51364112e-02,  1.00528157e+00,
          3.75859350e-01,  8.51481438e-01, -1.42668962e-01, -4.18564379e-02,
          6.08797520e-02,  1.62551805e-01,  2.23527923e-01, -1.78823201e-03,
          4.50995684e-01, -2.37530380e-01, -2.69343853e-01,  2.61102200e-01,
         -2.57360864e+00,  3.02977443e-01,  3.86746109e-01,  2.72833973e-01,
          3.21006864e-01,  6.48979843e-02, -3.15890521e-01, -1.45636395e-01,
         -2.64472097e-01,  1.19071901e+00,  7.90163353e-02, -2.76822671e-02,
          1.14128292e-01, -7.40209594e-04,  4.35432523e-01, -3.10341883e-02,
          2.17780262e-01,  7.02084422e-01,  2.98920069e-02, -4.66818005e-01,
         -1.28633514e-01,  2.89398372e-01, -1.15014732e-01,  3.07614833e-01,
          4.92659003e-01,  3.04484963e-01, -8.00469935e-01,  1.34866834e-01,
         -5.82501054e-01,  8.34716797e-01, -3.21505725e-01,  1.92138225e-01,
         -7.66735077e-02,  8.88491213e-01, -1.86379999e-01,  4.00690407e-01],
        [ 4.88946855e-01,  2.60339230e-01,  7.24073574e-02,  2.00816408e-01,
          2.71944791e-01, -1.51762441e-01, -1.79436550e-01,  4.47633713e-01,
          2.48434186e-01,  2.54889786e-01,  3.54483694e-01,  5.18203735e-01,
          6.77662611e-01,  3.68306160e-01,  5.47302008e-01,  1.46432757e-01,
          2.50548959e-01,  1.29683539e-01,  2.16628969e-01,  1.06934480e-01,
          1.73040226e-01,  1.96693301e-01,  1.87752500e-01,  8.06029499e-01,
          3.40997986e-02,  5.29780626e-01,  9.89805609e-02,  2.75516063e-01,
         -2.23718047e+00, -2.36317944e-02,  5.26788294e-01,  3.56938928e-01,
          3.80675614e-01,  2.62154460e-01,  3.59499842e-01, -9.40146297e-02,
          1.61807209e-01,  1.93353802e-01,  1.46806031e-01,  3.28952104e-01,
          4.69561219e-01, -1.94296867e-01,  4.37392682e-01,  2.21740887e-01,
          2.76418328e-01, -1.51914388e-01,  2.98237085e-01,  4.37440425e-01,
          2.10303530e-01,  3.31997961e-01,  5.60385883e-01,  4.50065166e-01,
         -2.26157874e-01, -1.64372727e-01,  3.33993852e-01,  3.82742733e-01,
          9.42960382e-02,  1.18957110e-01,  4.12093967e-01,  4.45325077e-01,
          2.72894263e-01, -4.74880710e-02,  6.33072078e-01, -6.01167046e-03],
        [ 3.15092415e-01,  2.45625362e-01,  1.25141338e-01,  3.20375234e-01,
          2.13272929e-01,  1.78446304e-02,  3.12721550e-01,  1.80294767e-01,
          7.96114057e-02,  1.20749153e-01,  2.96799093e-01,  3.44896257e-01,
          9.52602848e-02,  3.06152493e-01,  5.18863976e-01,  4.83877301e-01,
          3.33137691e-01,  2.98338562e-01,  3.43336940e-01, -9.20509622e-02,
          1.60935342e-01,  3.55694801e-01,  3.67381483e-01,  4.98973370e-01,
          2.85067439e-01,  3.04178506e-01,  2.97820568e-01,  3.78826946e-01,
         -2.04565883e+00,  3.39942187e-01,  5.61451018e-01,  1.82167441e-01,
          2.84137785e-01,  6.54615760e-01,  4.29946274e-01,  4.63776290e-02,
          1.60107672e-01,  3.32432210e-01,  7.37644285e-02,  1.78659007e-01,
          4.20172930e-01,  3.78236324e-01,  3.88496250e-01,  3.23066145e-01,
          4.57601517e-01,  4.01433766e-01,  2.11384937e-01,  3.89359474e-01,
          1.01739466e-01,  4.14737761e-01,  3.06361586e-01,  1.20544635e-01,
          1.61366731e-01,  4.34631228e-01,  2.99117535e-01,  2.72031218e-01,
          5.89464009e-02,  2.03927413e-01,  3.17846328e-01,  2.62769699e-01,
          4.76920277e-01,  3.02744120e-01,  4.93431062e-01,  5.05203724e-01]])
================================================================================
moe.topk_idx                             CHECK_SUCCESS: True eq_num/sum: 104/104
============================================================
tensor([[28, 23, 30, 37, 35,  7, 62, 17],
        [30, 53, 16, 17, 23, 46, 42, 15],
        [30, 10, 23, 62, 34,  8, 47,  3],
        [30, 47, 33, 62, 34, 23, 63, 10],
        [32, 61, 24, 52, 45, 17, 53, 15],
        [ 3, 47, 13, 46, 11, 62, 38, 39],
        [14, 43, 11, 54,  6, 40, 53, 17],
        [42,  9, 48, 29, 54, 61, 40, 11],
        [18, 62,  9,  8, 54, 50,  7, 12],
        [58, 47, 56, 25, 37,  4,  8, 50],
        [37, 15, 61, 17, 57, 45, 42, 52],
        [23, 12, 62, 50, 25, 30,  0, 40],
        [33, 30, 63, 62, 23, 60, 44, 53]], dtype=torch.int32)
--------------------------------------------------------------------------------
tensor([[28, 23, 30, 37, 35,  7, 62, 17],
        [30, 53, 16, 17, 23, 46, 42, 15],
        [30, 10, 23, 62, 34,  8, 47,  3],
        [30, 47, 33, 62, 34, 23, 63, 10],
        [32, 61, 24, 52, 45, 17, 53, 15],
        [ 3, 47, 13, 46, 11, 62, 38, 39],
        [14, 43, 11, 54,  6, 40, 53, 17],
        [42,  9, 48, 29, 54, 61, 40, 11],
        [18, 62,  9,  8, 54, 50,  7, 12],
        [58, 47, 56, 25, 37,  4,  8, 50],
        [37, 15, 61, 17, 57, 45, 42, 52],
        [23, 12, 62, 50, 25, 30,  0, 40],
        [33, 30, 63, 62, 23, 60, 44, 53]])
================================================================================
moe.topk_weights                         CHECK_SUCCESS: False eq_num/sum: 55/104
============================================================
tensor([[0.89314222, 0.00795182, 0.00573437, 0.00306247, 0.00218231, 0.00173785,
         0.00188595, 0.00166032],
        [0.04868369, 0.04801342, 0.03795740, 0.02411238, 0.02354512, 0.02308663,
         0.02255029, 0.02295703],
        [0.03320679, 0.02669563, 0.02575571, 0.02382541, 0.02333382, 0.02210402,
         0.02107071, 0.02034780],
        [0.02988647, 0.02195129, 0.02159173, 0.02018055, 0.02033397, 0.01993908,
         0.01892041, 0.01862800],
        [0.03592293, 0.03488269, 0.03273304, 0.03098991, 0.02392364, 0.02258179,
         0.02207018, 0.02363678],
        [0.02688838, 0.02611651, 0.02549657, 0.02471845, 0.02571213, 0.02400526,
         0.02245609, 0.02227668],
        [0.02655450, 0.02450175, 0.02586477, 0.02539790, 0.02463210, 0.02208440,
         0.02146751, 0.01990996],
        [0.03568831, 0.02865195, 0.02613868, 0.02649775, 0.02401702, 0.02143795,
         0.02008394, 0.02093698],
        [0.03372585, 0.02636831, 0.02301091, 0.02283564, 0.02410029, 0.02146127,
         0.02071029, 0.02047274],
        [0.03052580, 0.02800822, 0.02573688, 0.02131384, 0.02091088, 0.02005831,
         0.01989165, 0.01955493],
        [0.04415686, 0.03668291, 0.03263942, 0.03145351, 0.03093060, 0.02708863,
         0.02074825, 0.02197023],
        [0.02697643, 0.02372660, 0.02269186, 0.02110100, 0.02046498, 0.02040383,
         0.01964615, 0.01926895],
        [0.02251859, 0.02051542, 0.01939333, 0.01916636, 0.01927288, 0.01885251,
         0.01849180, 0.01807188]])
--------------------------------------------------------------------------------
tensor([[0.89314222, 0.00795182, 0.00573437, 0.00306247, 0.00218231, 0.00173785,
         0.00188595, 0.00166032],
        [0.04868368, 0.04801342, 0.03795740, 0.02411238, 0.02354512, 0.02308662,
         0.02255028, 0.02295702],
        [0.03320679, 0.02669563, 0.02575571, 0.02382541, 0.02333382, 0.02210402,
         0.02107071, 0.02034780],
        [0.02988647, 0.02195130, 0.02159174, 0.02018055, 0.02033397, 0.01993909,
         0.01892041, 0.01862801],
        [0.03592293, 0.03488269, 0.03273304, 0.03098991, 0.02392364, 0.02258179,
         0.02207018, 0.02363678],
        [0.02688838, 0.02611651, 0.02549658, 0.02471845, 0.02571213, 0.02400526,
         0.02245609, 0.02227668],
        [0.02655450, 0.02450175, 0.02586477, 0.02539790, 0.02463210, 0.02208440,
         0.02146751, 0.01990996],
        [0.03568831, 0.02865195, 0.02613868, 0.02649775, 0.02401702, 0.02143795,
         0.02008394, 0.02093698],
        [0.03372585, 0.02636831, 0.02301091, 0.02283564, 0.02410029, 0.02146127,
         0.02071029, 0.02047274],
        [0.03052580, 0.02800822, 0.02573688, 0.02131384, 0.02091088, 0.02005831,
         0.01989165, 0.01955493],
        [0.04415686, 0.03668291, 0.03263942, 0.03145351, 0.03093059, 0.02708862,
         0.02074825, 0.02197023],
        [0.02697643, 0.02372660, 0.02269186, 0.02110100, 0.02046498, 0.02040383,
         0.01964615, 0.01926896],
        [0.02251859, 0.02051542, 0.01939333, 0.01916636, 0.01927288, 0.01885251,
         0.01849180, 0.01807188]])
