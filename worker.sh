PADDLE_TRAINER_ID=0 PADDLE_TRAINERS_NUM=1 TRAINER_INSTANCES_NUM=1 TRAINER_INSTANCES=0.0.0.0 ENABLE_FASTDEPLOY_LOAD_MODEL_CONCURRENCY=0 LOAD_STATE_DICT_THREAD_NUM=1 PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python FLAGS_use_append_attn=1 NCCL_ALGO=Ring ELLM_DYNAMIC_MODE=1 /root/miniconda3/envs/hcr/bin/python -u -m paddle.distributed.launch --nnodes 1 --devices 0 /root/miniconda3/envs/hcr/lib/python3.10/site-packages/fastdeploy/engine/../worker/worker.py --max_num_seqs 8 --max_model_len 8192 --gpu_memory_utilization 0.2 --model_name_or_path /share/project/hcr/models/wenxinyiyan/ernie34T-4l --device_ids 0 --engine_worker_queue_port 8002 --total_block_num 136 --block_size 64 --enc_dec_block_num 2 --eos_tokens_lens 1 --pad_token_id 0 --engine_pid 1345329 --do_profile 1 --dynamic_load_weight 0 --max_num_batched_tokens 8192 --kv_cache_ratio 0.75 --dtype bfloat16 2>log/launch_worker.log
